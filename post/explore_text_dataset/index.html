<!DOCTYPE html>
<html class="no-js" lang="zh-CN">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>论文解读：Exploring text datasets by visualizing relevant words</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<meta name="generator" content="Hugo 0.52" />
	<meta property="og:title" content="论文解读：Exploring text datasets by visualizing relevant words" />
<meta property="og:description" content="在做机器学习使用新数据集时，我们首先要知道它的特点，一个可以快速可靠地深入了解所选文档的内容，并区分它们类别的工具十分重要。 在这篇论文，作者从文本集合中提取“相关词”，以概括属于某个类别（或在unlabeled数据集下为聚类的组）的文档的内容，并在词云中可视化它们。 作者比较了三种提取相关单词的方法，并使用两个数据集验证了模型的可用性。论文链接：https://arxiv.org/pdf/1707.05261.pdf，论文代码：https://github.com/cod3licious/textcatvis" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://xpgreat.com/post/explore_text_dataset/" /><meta property="article:published_time" content="2020-11-19T15:14:26&#43;08:00"/>
<meta property="article:modified_time" content="2020-11-19T15:14:26&#43;08:00"/>

	
	<link rel="stylesheet" href="/css/highlight.css">
	<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	<link rel="shortcut icon" href="/favicon.ico">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-130422706-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="XP&#39;s Blog" rel="home">
				<div class="logo__title">XP&#39;s Blog</div>
				<div class="logo__tagline">积跬步 以至千里</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">首页</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/archive/">归档</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/links/">友链</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/about/">关于</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/license/">许可</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">论文解读：Exploring text datasets by visualizing relevant words</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 16 16"><path d="m8-.0000003c-4.4 0-8 3.6-8 8 0 4.4000003 3.6 8.0000003 8 8.0000003 4.4 0 8-3.6 8-8.0000003 0-4.4-3.6-8-8-8zm0 14.4000003c-3.52 0-6.4-2.88-6.4-6.4000003 0-3.52 2.88-6.4 6.4-6.4 3.52 0 6.4 2.88 6.4 6.4 0 3.5200003-2.88 6.4000003-6.4 6.4000003zm.4-10.4000003h-1.2v4.8l4.16 2.5600003.64-1.04-3.6-2.1600003z"/></svg>
	<time class="meta__text" datetime="2020-11-19T15:14:26">November 19, 2020</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="/categories/%e8%ae%ba%e6%96%87" rel="category">论文</a>, <a class="meta__link" href="/categories/%e8%ae%a1%e7%ae%97%e6%9c%ba" rel="category">计算机</a></span>
</div>
</div>
		</header><div class="content post__content clearfix">
			<p>在做机器学习使用新数据集时，我们首先要知道它的特点，一个可以快速可靠地深入了解所选文档的内容，并区分它们类别的工具十分重要。 在这篇论文，作者从文本集合中提取“相关词”，以概括属于某个类别（或在unlabeled数据集下为聚类的组）的文档的内容，并在词云中可视化它们。 作者比较了三种提取相关单词的方法，并使用两个数据集验证了模型的可用性。论文链接：<a href="https://arxiv.org/pdf/1707.05261.pdf，论文代码：https://github.com/cod3licious/textcatvis">https://arxiv.org/pdf/1707.05261.pdf，论文代码：https://github.com/cod3licious/textcatvis</a></p>

<h2 id="目标">目标</h2>

<p>提供一个文件数据集，输出一组词云，展示最能够区分每个文件类别的词。这里的数据集可以是标注的或是未标注的，对未标注的数据集作者先进行了聚类。</p>

<p><img src="/media/image-20201119154330899.png" alt="image-20201119154330899" /></p>

<p>上图是作者论文中的图片，五个词云分别表示最能代表论文五个部分（Abstract, Introduction, Methods, Results, Discussion，即文件类别）的词。</p>

<h2 id="方法">方法</h2>

<h3 id="数据预处理和特征提取">数据预处理和特征提取</h3>

<p>首先对所有文件进行1.小写化 2. 删除非字母数字的字符。然后逐段用tfidf转换为bag-of-words（BOW）特征向量$\bold x_k \in \bold R^T \forall k \in {1,\dots,N}$，其中$k$是文件编号，$T$是该文件包含的词汇数（vocabulary，即去重词数），$N$是文件数。表示文件$k$的特征向量里对应单词$t<em>i$的值$\bold x</em>{ki} = tf(t_i) idf(t_i)$。</p>

<h4 id="tf-idf">TF-IDF</h4>

<p>Term Frequency-Inverse Document Frequency，词频-逆文件频率，是一种用于资讯检索与资讯探勘的常用加权技术。TF-IDF是一种统计方法，用以评估一单词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。即<strong>一个词语在一篇文件中出现次数越多, 同时在所有文档中出现次数越少, 越能够代表该文件</strong>。一般做归一化处理，公式如下：
$$
tf(t_i)=\frac{在某一文件中词t_i出现的次数}{该文件中所有的词数目}
$$</p>

<p>$$
idf(t_i)=\log(\frac{数据集的文件总数}{包含词t_i的文件数})=\log\frac{|N|}{|{k\in N:t_i\in k}|}
$$</p>

<p>有时为了保证$idf$分母不为零，可以在分母上加一。</p>

<h3 id="未标注数据集聚类">未标注数据集聚类</h3>

<p>对于未标注的数据集，首先要聚类成多个cluster，然后针对每个cluster计算相关单词。作者采用的是DBSCAN（density-based spatial clustering of applications with noise，<a href="https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf），首先把tfidf向量用线性PCA降维到250维，然后对特征做交叉，再计算向量间的距离（1">https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf），首先把tfidf向量用线性PCA降维到250维，然后对特征做交叉，再计算向量间的距离（1</a> - cosine similarity）。对于聚类时使用的距离门槛（threshold），作者经过实验推荐最低cosine similarity为0.45.</p>

<h3 id="计算相关单词-relevant-word">计算相关单词（relevant word）</h3>

<p>确定相关单词分为两步，第一步是计算描述相关性的relevance score $r_c$，第二步时根据$r_c$给所有单词排序，越高代表越相关。为了计算$r_c$，作者比较了三种方法：</p>

<ol>
<li>通过汇总组中所有文档的原始tf-idf特征；</li>
<li>通过汇总由某些分类器（SVM+LRP）加权的这些特征；</li>
<li>分别计算每个单词在该类和其他类出现的文件数量，进而求出$r_c$。</li>
</ol>

<h4 id="突出tfidf特征法-salient-tf-idf-features">突出tfidf特征法（Salient tf-idf features）</h4>

<p>最直接简单的方法，对类别$c$计算$r_c$的公式为：
$$
r_c (t<em>i) = \sum</em>{k:y<em>k=c}\bold x</em>{ki}=\sum_{k:y_k=c}tf_k(t_i)idf_k(t_i)
$$
即将所有属于类别$c$的文件$k$中的单词$t_i$的tf-idf值加起来作为这个类别中该单词的relevance score。这样分数最高的单词在该类别的文件中出现频率最高，且不会在大多数其他文件里出现（否则idf值会很低）。然而，一个可能的问题是，高分词在其他类别的文件中出现频率也差不多，这对idf的值影响不大，但意味着在其他类别中该词也会被判定为relevant word，这与relevant word的定义矛盾（最能用来区分不同类别的词）。</p>

<h4 id="svm-lrp-decomposed-classifier-scores">SVM+LRP（Decomposed classifier scores）</h4>

<p>分为两步，第一步找到一个线性分类器，利用tfidf特征将文件分类。即对类$c$，找到$\bold w_c$，最优化分类器：
$$
\hat y<em>k  = \mathop{\arg \max}</em>{c} \ b_c + \bold w_c^T\bold x_k
$$
优化好分类器后，计算relevance score：
$$
r_c(t<em>i) = \sum</em>{k:y<em>k=c}\left( \bold w</em>{ci} \bold x_{ki} + \frac{b_c}{T}\right)
$$
其中$T$是词汇数。</p>

<p>在优化分类器时，作者选择了SVM，并提出，也可以用其他的线性分类器比如逻辑回归，甚至DNN。作者强调，只有在分类器精确度相当高的时候，这个方法找出来的相关词汇才有意义，所以分类器的精确度比简便更加重要。</p>

<h5 id="layerwise-relevance-propagation-lrp">Layerwise relevance propagation（LRP）</h5>

<p>是一个计算相关性，并将相关性逐层向后传播的过程。首先将网络模型看成一个拓扑图结构，在计算一个节点 a 和输入的节点之间的相关性时，将 a 点的数值作为相关性，并且计算与 a 点相连的上一层节点在生成 a 点时所占的权重，将 a 的相关性逐层向后传播，直到输入层。作者用下图的例子告诉了我们：</p>

<p><img src="/media/image-20201119212624565.png" alt="image-20201119212624565" style="zoom:50%;" /></p>

<p>如果要计算 $v_1$ 和 $u_1$ 之间的相关性，首先计算 $v_1 $和 $z_1$, $z_2$ 之间的相关性，再将 $v_1$ 和$z_1$, $z_2$ 的相关性传递到 $u_1$, 从而求得 $v_1$ 和 $u_1$ 之间的相关性。</p>

<h5 id="support-vector-machine-svm-支持向量机">Support vector machine （SVM，支持向量机）</h5>

<p>是一种二分类模型，它的基本模型是定义在特征空间上的<strong>间隔最大</strong>的<strong>线性分类器</strong>，间隔最大使它有别于感知机；SVM还包括<strong>核技巧</strong>，这使它成为实质上的非线性分类器。SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。</p>

<p>SVM学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。如下图所示，$\bold w \bold x + b = 0$即为分离超平面，对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的。</p>

<p><img src="/media/image-20201119213025858.png" alt="image-20201119213025858" /></p>

<p>SVM有一个重要性质：<strong>训练完成后，大部分的训练样本都不需要保留，最终模型仅与支持向量有关。</strong></p>

<p>算法如下：</p>

<p><strong>输入</strong>：训练数据集 $T={(\bold x_1,y_1),(\bold x_2,y_2),\dots,(\bold x_n,y_n)}$其中，$\bold x_i \in \bold R^n, y_i \in {1,-1},i = 1,2,\dots,n$；</p>

<p><strong>输出</strong>：分离超平面和分类决策函数</p>

<p>（1）选择惩罚参数$C &gt; 0$ ，构造并求解凸二次规划问题
$$
\min<em>\alpha \frac{1}{2}\sum</em>{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j(\bold x_i\bold x<em>j) - \sum</em>{i=1}^N\alpha<em>i<br />
s.t.\ \sum</em>{i=1}^N\alpha_iy_i=0<br />
0\le \alpha_i\le C, i=1,2,\dots,N
$$
得到最优解$\bold\alpha^<em>=(\alpha_1^</em>,\alpha_2^<em>,\dots,\alpha_N^</em>)^T$</p>

<p>（2）计算
$$
\mathbf {\omega} ^* = \sum_{i=1}^N\alpha_i^*y_i\bold x_i
$$</p>

<p>选择$\bold \alpha^<em>$的一个分量$\bold \alpha_j^</em>$满足条件$0&lt;\bold \alpha_j^* &lt; C$，计算
$$
b^* = y<em>j - \sum</em>{i=1}^N\alpha_i^<em>y_i(\bold x_i\bold x_j)
$$
（3）求分离超平面
$$
\bold \omega ^</em> \bold x + b^* = 0
$$
分类决策函数：
$$
f(\bold x) = sign(\bold\omega^<em>\bold x +b^</em>)
$$</p>

<h4 id="词-文件数量法-distinctive-words">词-文件数量法（Distinctive words）</h4>

<p>作者引入了两个概念：TPR（True Positive Rate，真阳性率）和FPR（假阳性率）。定义分别为
$$
TPR_c(t_i) = \frac{类别为c且t_i的tfidf值大于0的文件数}{类别为c的文件数}=\frac {|{k:y<em>k=c\ \and \ \bold x</em>{ki} &gt; 0}|}{|{k:y_k=c}|}<br />
FPR_c(t_i) = mean({TPR_l(t_i):l\ne c})+std({TPR_l(t_i):l\ne c})
$$
最终目的是找出在目标类中出现频繁（TPR高），且在非目标类中出现不频繁（FPR低）的词，需要一个度量这一性质的函数。一种直接的方法是直接算差值：
$$
r_c_diff(t_i) = \max {TPR_c(t_i)-FPR_c(t_i),0}
$$
这种方法存在一个问题，即只考虑了两个率的绝对差值，未考虑相对差，即如果1. TPR=0.9，FPR=0.8；2. TPR=0.2，FPR=0.1，这种量度会认为他们一样重要，但显然前者对于后者，TPR和FPR相差过近。因此引入基于除法的算法：
$$
r_c_quot(t_i) = \frac{\min{\max{z_c(t_i),1},4} -1}{3} <br />
where\ z_c(t_i) = \frac{TPR_c(t_i)}{\max{FPR_c(t_i),\epsilon}}, \epsilon是一个极小值，用来避免除数为零
$$
综合二者，得到既考虑相对又考虑绝对差异的度量：
$$
r_c_dist(t_i) = 0.5(r_c_diff(t_i)+r_c_quot(t_i))
$$
rc-TPR-FPR关系图：</p>

<p><img src="/media/image-20201119232608223.png" alt="image-20201119232608223" style="zoom:50%;" /></p>

<h2 id="结论">结论</h2>

<p>作者用scientific publications（标记的，主题、格式分类）和New York Times article（未标记的，寻找热度主题）两个数据集验证了算法的可行性。该方法快速且可靠，更重要的是，即使许多cluster仅包含很少的样本，也有可能可以识别出relevant words，而用分类算法很难达到这个效果。</p>

<h2 id="参考">参考</h2>

<p><a href="https://zhuanlan.zhihu.com/p/31886934">https://zhuanlan.zhihu.com/p/31886934</a></p>

<p><a href="https://www.sohu.com/a/150681957_114778">https://www.sohu.com/a/150681957_114778</a></p>
		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 16 16"><path d="M16 9.5c0 .373-.24.74-.5 1l-5 5c-.275.26-.634.5-1 .5-.373 0-.74-.24-1-.5L1 8a2.853 2.853 0 0 1-.7-1C.113 6.55 0 5.973 0 5.6V1.4C0 1.034.134.669.401.401.67.134 1.034 0 1.4 0h4.2c.373 0 .95.113 1.4.3.45.187.732.432 1 .7l7.5 7.502c.26.274.5.632.5.998zM3.5 5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/nlp/" rel="tag">NLP</a></li>
	</ul>
</div>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="XIONG Ping avatar" src="/img/head.jpg" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		
		<span class="authorbox__name">XIONG Ping</span>
	</div>
	<div class="authorbox__description">
		柏林工业大学的硕士生，专业经济工程计算机方向。
	</div>
</div>


<section class="comments">
	

	<div id="lv-container" data-id="city" data-uid="MTAyMC80MzkyNy8yMDQ2Mw==">
		<script type="text/javascript">
	   (function(d, s) {
	       var j, e = d.getElementsByTagName(s)[0];

	       if (typeof LivereTower === 'function') { return; }

	       j = d.createElement(s);
	       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
	       j.async = true;

	       e.parentNode.insertBefore(j, e);
	   	})(document, 'script');
		</script>
		<noscript>为正常使用评论功能请激活JavaScript</noscript>
	</div>

</section>


			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="Enter to SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="http://xpgreat.com/" />
	</form>
</div>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=a&t=tt&d=vn9XwpQC1mo0ktLzWyesdzglYxafoYqO_-XrgyT-k8w&co=ffffff&cmo=3acc3a&cmn=008eff&ct=808080'></script>
<div class="widget-social widget">
	<h4 class="widget-social__title widget__title">Social</h4>
	<div class="widget-social__content widget__content">
		<div class="widget-social__item widget__item">
			<a class="widget-social__link widget__link btn" title="Telegram" rel="noopener noreferrer" href="https://t.me/xphahaha" target="_blank">
				<svg class="widget-social__link-icon icon-telegram" viewBox="0 0 132 110" width="24" height="24"><path fill="#ddd" d="M50 103c-4 0-3-1-5-5L34 60l88-52"/><path fill="#aaa" d="M50 103c3 0 4-1 6-3l16-16-20-12"/><path fill="#fff" d="M52 72l48 36c6 3 10 2 11-5l20-93c2-8-3-11-8-9L7 45c-8 4-8 8-1 10l29 9 69-43c3-2 6-1 4 1"/></svg>
				<span></span>
			</a>
		</div>
		<div class="widget-social__item widget__item">
			<a class="widget-social__link widget__link btn" title="Email" href="mailto:xiong.ping.xp@qq.com">
				<svg class="widget-social__link-icon icon-mail" viewBox="0 0 416 288" width="24" height="24" fill="#fff"><path d="m0 16v256 16h16 384 16v-16-256-16h-16-384-16zm347 16-139 92.5-139-92.5zm-148 125.5 9 5.5 9-5.5 167-111.5v210h-352v-210z"/></svg>
				<span></span>
			</a>
		</div>
	</div>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/post/explore_text_dataset/">论文解读：Exploring text datasets by visualizing relevant words</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/hive_windowfunc/">Hive窗口函数总结</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/workflow_ml/">机器学习的工作流程</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/tip_inst_tf/">安装TensorFlow时踩的一个小坑</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/jupyter_install_package/">在Jupyer Notebook里安装包</a></li>
		</ul>
	</div>
</div>
<div class="widget-categories widget">
	<h4 class="widget__title">Categories</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/categories/%e5%a4%a7%e6%95%b0%e6%8d%ae">大数据</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e6%95%b0%e5%ad%a6">数学</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e6%95%b0%e6%8d%ae%e5%ba%93">数据库</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e6%9d%82%e8%b0%88">杂谈</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e7%bb%9f%e8%ae%a1%e5%ad%a6">统计学</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e7%bd%91%e7%bb%9c">网络</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e8%8b%b1%e8%af%ad">英语</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e8%ae%a1%e7%ae%97%e6%9c%ba">计算机</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e8%ae%ba%e6%96%87">论文</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/%e9%87%91%e8%9e%8d">金融</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/hive" title=" Hive ">Hive</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/html" title=" Html ">Html</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/linux" title=" Linux ">Linux</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/nlp" title=" Nlp ">Nlp</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/ssh" title=" Ssh ">Ssh</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/tensorflow" title=" Tensorflow ">Tensorflow</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e4%bb%b7%e6%a0%bc%e9%a2%84%e6%b5%8b" title=" 价格预测 ">价格预测</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e5%8d%9a%e5%ae%a2" title=" 博客 ">博客</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e6%8a%80%e5%b7%a7" title=" 技巧 ">技巧</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e6%8a%95%e8%b5%84" title=" 投资 ">投资</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e6%9c%9f%e6%9d%83" title=" 期权 ">期权</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0" title=" 机器学习 ">机器学习</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e7%ae%97%e6%b3%95" title=" 算法 ">算法</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e7%ba%bf%e6%80%a7%e4%bb%a3%e6%95%b0" title=" 线性代数 ">线性代数</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e8%ae%ba%e6%96%87" title=" 论文 ">论文</a>
		
		
			<a class="widget-taglist__link widget__link btn" href="/tags/%e9%a3%8e%e9%99%a9%e7%ae%a1%e7%90%86" title=" 风险管理 ">风险管理</a>
		
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2018 - 2020 XP. 
			本博客采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>许可。<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="/media/license.jpg" width="50px"></a>
		</div>
	</div>


</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>