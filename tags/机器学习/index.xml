<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on XP&#39;s Blog</title>
    <link>http://xpgreat.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on XP&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 29 Aug 2021 10:56:18 +0200</lastBuildDate><atom:link href="http://xpgreat.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LRP简介</title>
      <link>http://xpgreat.com/p/lrp/</link>
      <pubDate>Sun, 29 Aug 2021 10:56:18 +0200</pubDate>
      
      <guid>http://xpgreat.com/p/lrp/</guid>
      <description>&lt;p&gt;机器学习的可解释性一直以来都是一个大问题，模型中的海量权重和连接关系让机器学习一直被视为黑盒模型。为了解决这个问题，Explainable AI （XAI）是一个前沿的研究方向。关于可解释性的研究，推荐这篇&lt;a class=&#34;link&#34; href=&#34;https://ieeexplore.ieee.org/document/9369420&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;综述&lt;/a&gt;。本文简要介绍解释深度神经网络（DNN）的算法LRP（Layerwise Relevance Propagation）。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GNN 图神经网络简介</title>
      <link>http://xpgreat.com/p/gnn/</link>
      <pubDate>Fri, 27 Aug 2021 23:40:00 +0200</pubDate>
      
      <guid>http://xpgreat.com/p/gnn/</guid>
      <description>&lt;p&gt;图神经网络是是一种基于图结构的广义神经网络。其实传统的神经网络也是可以处理图数据，只需要进行前期合理的embedding即可，那么为什么还需要GNN呢？GNN其实属于一种embedding算法，它通过在整张图上&lt;strong&gt;传递、转换、聚合&lt;/strong&gt;节点的特征信息，从而生成单节点的embedding。本文简要介绍GNN，力求通俗易懂，需要更详细的研究GNN的话，推荐一篇2019年的综述&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1901.00596&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;A Comprehensive Survey on Graph Neural Networks&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>利用sklearn构建tfidf向量</title>
      <link>http://xpgreat.com/p/tfidf_python/</link>
      <pubDate>Tue, 24 Nov 2020 11:22:02 +0800</pubDate>
      
      <guid>http://xpgreat.com/p/tfidf_python/</guid>
      <description>在自然语言处理中，第一步需要面对的就是词向量特征的提取。语言的特征提取在sklearn模块中有相当完善的方法和模块，本文先利用CountVectorizer提取词汇，再用TfidfTransformer计算TFIDF向量。之所以选择CountVectorizer而不自行写一个代码，是因为在使用时维度很容易超过10w，产生的bag-of-words向量特别稀疏，需要耗费极大的内存，而sklearn实现了一个稀疏矩阵的存储形式，可以极大的加速和降低消耗。
构建Bag-of-words词汇矩阵 from sklearn.feature_extraction.text import CountVectorizer #测试用字符串list s_l = [&amp;#39;Relevant words for each class or cluster are identified by computing a relevancy score rc for every word ti based on the documents in the class&amp;#39;, &amp;#39;or cluster and then selecting the highest scoring&amp;#39;, &amp;#39;words. These scores can be computed either by-89&amp;#39;, &amp;#39;aggregating the raw tf-idf features of all documents&amp;#39;, &amp;#39;in the group (Section 2.3.1), by aggregating these&amp;#39;, &amp;#39;features weighted by some classifier’s parameters&amp;#39;, &amp;#39;(Section 2.</description>
    </item>
    
    <item>
      <title>论文解读：Exploring text datasets by visualizing relevant words</title>
      <link>http://xpgreat.com/p/explore_text_dataset/</link>
      <pubDate>Thu, 19 Nov 2020 15:14:26 +0800</pubDate>
      
      <guid>http://xpgreat.com/p/explore_text_dataset/</guid>
      <description>&lt;p&gt;在做机器学习使用新数据集时，我们首先要知道它的特点，一个可以快速可靠地深入了解所选文档的内容，并区分它们类别的工具十分重要。 在这篇论文，作者从文本集合中提取“相关词”，以概括属于某个类别（或在unlabeled数据集下为聚类的组）的文档的内容，并在词云中可视化它们。 作者比较了三种提取相关单词的方法，并使用两个数据集验证了模型的可用性。&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1707.05261.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;论文链接&lt;/a&gt;，&lt;a class=&#34;link&#34; href=&#34;https://github.com/cod3licious/textcatvis&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;论文代码&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>机器学习的工作流程</title>
      <link>http://xpgreat.com/p/workflow_ml/</link>
      <pubDate>Sun, 15 Mar 2020 16:25:12 +0800</pubDate>
      
      <guid>http://xpgreat.com/p/workflow_ml/</guid>
      <description>&lt;p&gt;最近在阅读François Chollet写的Deep Learning with Python. 书中有很多经验性的技巧和归纳，其中4.5写的Machine Learning的工作流程归纳的很好，看完深有启发，摘录于此。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>安装TensorFlow时踩的一个小坑</title>
      <link>http://xpgreat.com/p/tip_inst_tf/</link>
      <pubDate>Sun, 15 Mar 2020 15:22:49 +0800</pubDate>
      
      <guid>http://xpgreat.com/p/tip_inst_tf/</guid>
      <description>&lt;p&gt;不记得之前安装的是什么版本，这次（2020/3）让&lt;code&gt;pip&lt;/code&gt;自动安装选择的是&lt;code&gt;2.1.0&lt;/code&gt;，但这个版本安装后使用&lt;code&gt;import tensorflow&lt;/code&gt;会报错，如下：&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>中短期电价预测模型简介</title>
      <link>http://xpgreat.com/p/epf_models/</link>
      <pubDate>Sat, 25 May 2019 17:35:01 +0200</pubDate>
      
      <guid>http://xpgreat.com/p/epf_models/</guid>
      <description>&lt;p&gt;从1981年的智利电力体制改革之后，英美等国先后进行了电力工业重组，这些努力导致了电力工业的市场化，促成了电力市场的形成，实现了资源的合理分配和社会效益的最大化。准确的电力价格对发电商、用户、监管者具有重要的意义。本文将常用的电价预测（EPF, Electricity Price Forecasting）模型进行了分类，并加以简介。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>递归神经网络</title>
      <link>http://xpgreat.com/p/rnn_lstm_gru/</link>
      <pubDate>Tue, 14 May 2019 10:48:15 +0200</pubDate>
      
      <guid>http://xpgreat.com/p/rnn_lstm_gru/</guid>
      <description>&lt;p&gt;递归神经网络是神经网络的一种，与其他神经网络不同点在于，它可以很好地处理序列数据，即前面的数据的输入与后面的输出是有关系的，比如一句话的语义理解。本文介绍了递归神经网络及其两个变种——LSTM和GRU，目的是梳理一下自己所理解的RRN，也希望能够给初次接触RRN的同学一点帮助。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>机器学习中的矩阵求导</title>
      <link>http://xpgreat.com/p/linalg_in_ml/</link>
      <pubDate>Thu, 17 Jan 2019 21:47:14 +0100</pubDate>
      
      <guid>http://xpgreat.com/p/linalg_in_ml/</guid>
      <description>&lt;p&gt;在学习机器学习的算法时，推导过程中往往会涉及矩阵或向量求导以及一些其他的线性代数的知识。比如在推导LDA算法的时候，就是把Fisher&amp;rsquo;s Criterion求导后置零得到的结果。另外在优化的时候经常会使用到梯度下降法，这与矩阵向量求导也是分不开的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>认知算法小结</title>
      <link>http://xpgreat.com/p/ca_short_summary/</link>
      <pubDate>Fri, 28 Dec 2018 20:57:51 +0100</pubDate>
      
      <guid>http://xpgreat.com/p/ca_short_summary/</guid>
      <description>&lt;p&gt;在认知算法课里学习了一些算法，比如NCC，感知算法，LDA等等，小结一下。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
