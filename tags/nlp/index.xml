<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP on XP&#39;s Blog</title>
    <link>https://xpgreat.com/tags/nlp/</link>
    <description>Recent content in NLP on XP&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 24 Nov 2020 11:22:02 +0800</lastBuildDate><atom:link href="https://xpgreat.com/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>利用sklearn构建tfidf向量</title>
      <link>https://xpgreat.com/p/tfidf_python/</link>
      <pubDate>Tue, 24 Nov 2020 11:22:02 +0800</pubDate>
      
      <guid>https://xpgreat.com/p/tfidf_python/</guid>
      <description>在自然语言处理中，第一步需要面对的就是词向量特征的提取。语言的特征提取在sklearn模块中有相当完善的方法和模块，本文先利用CountVectorizer提取词汇，再用TfidfTransformer计算TFIDF向量。之所以选择CountVectorizer而不自行写一个代码，是因为在使用时维度很容易超过10w，产生的bag-of-words向量特别稀疏，需要耗费极大的内存，而sklearn实现了一个稀疏矩阵的存储形式，可以极大的加速和降低消耗。
构建Bag-of-words词汇矩阵 from sklearn.feature_extraction.text import CountVectorizer #测试用字符串list s_l = [&amp;#39;Relevant words for each class or cluster are identified by computing a relevancy score rc for every word ti based on the documents in the class&amp;#39;, &amp;#39;or cluster and then selecting the highest scoring&amp;#39;, &amp;#39;words. These scores can be computed either by-89&amp;#39;, &amp;#39;aggregating the raw tf-idf features of all documents&amp;#39;, &amp;#39;in the group (Section 2.3.1), by aggregating these&amp;#39;, &amp;#39;features weighted by some classifier’s parameters&amp;#39;, &amp;#39;(Section 2.</description>
    </item>
    
    <item>
      <title>论文解读：Exploring text datasets by visualizing relevant words</title>
      <link>https://xpgreat.com/p/explore_text_dataset/</link>
      <pubDate>Thu, 19 Nov 2020 15:14:26 +0800</pubDate>
      
      <guid>https://xpgreat.com/p/explore_text_dataset/</guid>
      <description>&lt;p&gt;在做机器学习使用新数据集时，我们首先要知道它的特点，一个可以快速可靠地深入了解所选文档的内容，并区分它们类别的工具十分重要。 在这篇论文，作者从文本集合中提取“相关词”，以概括属于某个类别（或在unlabeled数据集下为聚类的组）的文档的内容，并在词云中可视化它们。 作者比较了三种提取相关单词的方法，并使用两个数据集验证了模型的可用性。&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1707.05261.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;论文链接&lt;/a&gt;，&lt;a class=&#34;link&#34; href=&#34;https://github.com/cod3licious/textcatvis&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;论文代码&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
