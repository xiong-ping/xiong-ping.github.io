<!DOCTYPE html>
<html lang="zh-CN">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Recurrent Neural Network'><title>递归神经网络</title>

<link rel='canonical' href='http://xpgreat.com/p/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='递归神经网络'>
<meta property='og:description' content='Recurrent Neural Network'>
<meta property='og:url' content='http://xpgreat.com/p/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/'>
<meta property='og:site_name' content='XP&#39;s Blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='机器学习' /><meta property='article:tag' content='算法' /><meta property='article:published_time' content='2019-05-14T10:48:15&#43;02:00'/><meta property='article:modified_time' content='2019-05-14T10:48:15&#43;02:00'/>
<meta name="twitter:title" content="递归神经网络">
<meta name="twitter:description" content="Recurrent Neural Network">
    </head>
    <body class="">
        <div class="container flex on-phone--column align-items--flex-start extended article-page with-toolbar">
            <aside class="sidebar left-sidebar sticky">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="切换菜单">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header class="site-info">
        
            <figure class="site-avatar">
                

                
                    
                    <img src="/img/head_hu7a5a8ce21e62abecbc7926aff8bd098a_4354_300x300_resize_q75_box.jpg" width="300"
                        height="300" class="site-logo" loading="lazy" alt="Avatar">
                

                <span class="emoji">✈</span>
            </figure>
        
        <h1 class="site-name"><a href="http://xpgreat.com/">XP&#39;s Blog</a></h1>
        <h2 class="site-description">积跬步 以至千里</h2>
    </header>

    <ol class="menu" id="main-menu">
        
        
        

        <li >
            <a href='/'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        

        <li >
            <a href='/about'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>About</span>
            </a>
        </li>
        
        

        <li >
            <a href='/archives'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        

        <li >
            <a href='/search'>
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        <li>
            <a href="https://util.xpgreat.com">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
                      <path stroke="none" d="M0 0h24v24H0z"></path>
                      <line x1="10" y1="18" x2="23" y2="5"></line>
                      <line x1="10" y1="18" x2="3" y2="9"></line>
                    </svg>
                <span>Utils</span>
            </a>
        </li>
    </ol>
</aside>
            <main class="main full-width">
    <div id="article-toolbar">
        <a href="http://xpgreat.com/" class="back-home">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



            <span>Back</span>
        </a>
    </div>

    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            
                <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/">计算机</a>
            
        
            
                <a href="/categories/%E6%95%B0%E5%AD%A6/">数学</a>
            
        
    </header>
    

    <h2 class="article-title">
        <a href="/p/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">递归神经网络</a>
    </h2>

    
    <h3 class="article-subtitle">
        Recurrent Neural Network
    </h3>
    <footer class="article-time">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



        <time class="article-time--published">May 14, 2019</time>
    </footer></div>
</header>

    <section class="article-content">
    <p>递归神经网络是神经网络的一种，与其他神经网络不同点在于，它可以很好地处理序列数据，即前面的数据的输入与后面的输出是有关系的，比如一句话的语义理解。本文介绍了递归神经网络及其两个变种——LSTM和GRU，目的是梳理一下自己所理解的RRN，也希望能够给初次接触RRN的同学一点帮助。</p>
<h2 id="其他神经网络的不足为什么需要rrn">其他神经网络的不足——为什么需要RRN？</h2>
<p><img src="/media/1_SL8FESMwzSy6QTrcIzcRYw.png" alt=""  /></p>
<p>传统神经网络的结构大多为输入-隐藏层（多个）-输出，即给定一组输入数据，输出结果，隐藏层像一个黑盒子，通过各种运算把输入的数据算成需要的结果。输入不同的数据运行两次，它们的结果是完全无关的。而有的时候我们需要处理一个序列，比如一个句子，它是单词的序列，要理解这句话中各个单词的意思，必须要结合语境，也就是要结合其他的单词的意思，一般情况下要结合这个单词前面的单词。例如前面两个词是我、吃，那么后面的一个词很大概率是一个表示食物的名词。</p>
<p>为了解决一些这样类似的问题，能够更好的处理序列的信息，RNN就诞生了。</p>
<h2 id="rnn的结构">RNN的结构</h2>
<p><img src="/media/v2-b0175ebd3419f9a11a3d0d8b00e28675_r.jpg" alt=""  /></p>
<p>循环神经网络也由输入层、隐藏层和输出层构成，这是神经网络的基本结构，不同的是它的隐藏层（也叫cell）可以连续的接收输入\(x\)，输出\(o\)，而贯穿其中的\(s\)可以存储这个网络的状态，也就是“记忆”到的前面发生的事情，利用它可以更加精准的预测后面的输出。</p>
<p><img src="/media/RNN20190514210119.png" alt=""  />
一个最简单的RNN结构如图所示，每一个cell输入一个\(x\)和一个\(s\)，输出两个同样的\(h\)，通过下列算法算出：</p>
<p>$$
\begin{aligned}
&amp;s_t = \tanh (Ws_{t-1} + Ux_t)
\\&amp;h_t = Vs_t
\end{aligned}
$$</p>
<p>这种简单的结构虽然可以达到记忆的效果，然而存在着一个致命的问题：<strong>梯度爆炸</strong>和<strong>梯度消失</strong>。即在多次循环后，利用梯度下降法调整，在求导的时候会出现\(\frac{\partial Loss}{\partial w_i} = \frac{\partial Loss}{\partial f_t}\frac{\partial f_t}{\partial f_{t-1}}&hellip;\frac{\partial f_i}{\partial w_i} \)，如果\(\frac{\partial f_t}{\partial f_{t-1}}\)部分大于或小于1，会出现类似1.01的99次方（或0.99的99次方）的问题，使得权重过大或过小，无法使用梯度下降。这一问题的根源就在于\(W\)和\(s\)之间的乘法运算。为了解决这一问题，<a class="link" href="/file/lstm.pdf" >Hochreiter, Schmidhuber（1997)</a>提出了LSTM。</p>
<h2 id="lstm">LSTM</h2>
<p>LSTM全称Long Short Time Memory RRN，长短期记忆循环神经网络，它本质上也是一个循环神经网络，只是cell不一样而已，如下图：
<img src="/media/LSTM20190514210208.png" alt=""  /></p>
<p>LSTM的关键之处在于cell的状态，也就是图中贯穿顶部的那条水平线。Cell的状态像是一条传送带，它贯穿整条链，其中只发生一些小的线性作用。信息流过这条线而不改变是非常容易的。但是，LSTM也有能力移除或增加信息到cell状态中，由被称为门的结构精细控制。门是一种让信息可选地通过的方法。它们由一个sigmoid(\( S(t)={\frac {1}{1+e^{-t}}}\))神经网络层和一个点乘操作组成。这里的sigmoid函数取0-1的值，充当了开关的作用，控制影响的程度。</p>
<h3 id="运行过程">运行过程</h3>
<p><img src="/media/v2-d7a679e66345c250ebcf9d53ba5be867_r.jpg" alt=""  />
从左往右看这幅图，首先第一步是决定我们需要从cell状态中扔掉什么样的信息。这个决策由一个称为“遗忘门（forget gate）”的sigmoid层决定。输入 \(h_{t-1}\) 和 \(x_t\) ，输出一个0和1之间的数。1代表“完全保留这个值”，而0代表“完全扔掉这个值”。比如对于一个基于上文预测最后一个词的语言模型。cell的状态可能包含当前主题的信息，来预测下一个准确的词。而当我们得到一个新的语言主题的时候，我们会想要遗忘旧的主题的记忆，应用新的语言主题的信息来预测准确的词。</p>
<p><img src="/media/v2-535a2df5db8ac715ee373209d7cbd346_r.jpg" alt=""  />
第二步是决定我们需要在cell state里存储什么样的信息。这个问题有两个部分。第一，一个sigmoid层调用“输入门（input gate）”以决定哪些数据是需要更新的。然后，一个\(tanh\)层为新的候选值创建一个向量 \(\tilde{C}_t\) ，这些值能够加入state中。下一步，我们要将这两个部分合并以创建对state的更新。</p>
<p>比如还是语言模型，可以表示为想要把新的语言主题的信息加入到cell state中，以替代我们要遗忘的旧的记忆信息。</p>
<p><img src="/media/v2-f2dccb5533133c5ff61a58a0e1a752ab_r.jpg" alt=""  />
在决定需要遗忘和需要加入的记忆之后，就可以更新旧的cell state \(C_{t-1}\) 到新的cell state \(C_t\) 了。在这一步，我们把旧的state  \(C_{t-1}\) 与 \(f_t\) 相乘，遗忘我们先前决定遗忘的东西，然后我们加上 \(i_t * \tilde{C}_t\) ，这可以理解为新的记忆信息，当然，这里体现了对状态值的更新度是有限制的，我们可以把 \(i_t\)  当成一个权重。</p>
<p><img src="/media/v2-9b77a873ce830ea4a3bdb0385fe275ef_r.jpg" alt=""  />
最后，我们需要决定要输出的东西。这个输出基于我们的cell state，但会是一个过滤后的值。首先，我们运行一个sigmoid层，这个也就是输出门（output gate），以决定cell state中的那个部分是我们将要输出的。然后我们把cell state放进\(tanh\)（将数值压到-1和1之间），最后将它与sigmoid门的输出相乘，这样我们就只输出了我们想要的部分了。</p>
<p>在LSTM中，状态\(S\)通过累加的方式来计算，\(S_t = \sum_{\tau=1}^t \Delta S_{\tau}\)，这样就不会是一直复合函数的形式了，它的导数也不是乘积的形式，这样就不会发生梯度消失的情况了。（具体论文：An Empirical Exploration of Recurrent Network Architectures 和 Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling）</p>
<h2 id="gru">GRU</h2>
<p>GRU全称Gated Recurrent Unit，循环门单元。和LSTM一样，他也只是个cell的种类，本质上是RNN，由 <a class="link" href="/file/gru.pdf" >Cho, et al. (2014)</a>提出。它将LSTM的遗忘门和输入门组合成了一个新的更新门，合并了cell state和hidden state，比LSTM更加简单（尽管稍微难理解一些）。</p>
<p><img src="/media/v2-f2716bc289734d8b545926b38a224692_r.jpg" alt=""  /></p>
<p>从左往右看，前两个门是reset gate和update gate，计算方法：</p>
<p>$$
\begin{aligned}
&amp;r_t = \sigma (W^rx_t + U^rh_{t-1})
\\&amp;z_t = \sigma (W^zx_t + U^zh_{t-1})
\end{aligned}
$$</p>
<p>reset gate控制在计算候选状态时使用多少前序的状态，update gate则表示计算新状态时候选状态和原状态各取多少比例（注意特殊的“1-”门，表示把\(z_t\)当作一个比例）。</p>
<h2 id="总结和比较">总结和比较</h2>
<p>RRN是神经网络的一个种类，LSTM和GRU是两种特殊的cell。与最基本的cell结构相比，LSTM和GRU都很好的解决了梯度爆炸和梯度消失的问题。对比LSTM，GRU的参数更少，因而训练稍快或需要更少的数据来泛化。另一方面，如果有足够的数据，LSTM的强大表达能力可能会产生更好的结果。<a class="link" href="https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1503.04069.pdf"  target="_blank" rel="noopener"
    >Greff, et al. (2015)</a>对流行的变种做了一个很好的比较，发现它们都是一样的。<a class="link" href="https://link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v37/jozefowicz15.pdf"  target="_blank" rel="noopener"
    >Jozefowicz, et al.(2015)</a>测试了超过一万中RNN结构，发现某些任务情形下，有些比LSTM工作得更好，但那也是比较特殊的时候。</p>
<p>总的来说，没有通用的最好的模型，只能通过具体的数据和问题来选择模型。如果研究的数据序列会相互影响，比如做词语预测，那么LSTM-RRN和GRU-RRN不失为一种很好的选择。</p>
<p><em>参考：</em></p>
<ul>
<li><a class="link" href="https://zhuanlan.zhihu.com/p/34203833"  target="_blank" rel="noopener"
    >深入理解lstm及其变种gru</a></li>
<li><a class="link" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"  target="_blank" rel="noopener"
    >Understanding LSTM Networks</a></li>
</ul>
</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
        
            <a href="/tags/%E7%AE%97%E6%B3%95/">算法</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-ND 4.0</span>
    </section>
    </footer>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
    integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"
    integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
    integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.querySelector(`.article-content`));"></script>
    
</article>

    <aside class="related-contents--wrapper">
    
    
        <h2 class="section-title">相关文章</h2>
        <div class="related-contents">
            <div class="flex article-list--tile">
                
                    
<article class="">
    <a href="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC/">
        
        

        <div class="article-details">
            <h2 class="article-title">机器学习中的矩阵求导</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/%E5%88%A9%E7%94%A8sklearn%E6%9E%84%E5%BB%BAtfidf%E5%90%91%E9%87%8F/">
        
        

        <div class="article-details">
            <h2 class="article-title">利用sklearn构建tfidf向量</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBexploring-text-datasets-by-visualizing-relevant-words/">
        
        

        <div class="article-details">
            <h2 class="article-title">论文解读：Exploring text datasets by visualizing relevant words</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/%E8%AE%A4%E7%9F%A5%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/">
        
        

        <div class="article-details">
            <h2 class="article-title">认知算法小结</h2>
        </div>
    </a>
</article>
                
                    
<article class="">
    <a href="/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/">
        
        

        <div class="article-details">
            <h2 class="article-title">机器学习的工作流程</h2>
        </div>
    </a>
</article>
                
            </div>
        </div>
    
</aside>


    
        
    

    <footer class="site-footer">
    <section class="copyright">&copy; 2020 XP&#39;s Blog</section>
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="1.1.0">Stack</a></b> designed by
        <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true" style="display:none">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
            </main>
        </div>
        <script src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"
    integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin="anonymous"></script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>
<link rel="stylesheet" href="/css/highlight/light.min.css" media="(prefers-color-scheme: light)">
<link rel="stylesheet" href="/css/highlight/dark.min.css" media="(prefers-color-scheme: dark)">

    </body>
</html>
