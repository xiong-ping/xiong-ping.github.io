[{"content":"在做机器学习使用新数据集时，我们首先要知道它的特点，一个可以快速可靠地深入了解所选文档的内容，并区分它们类别的工具十分重要。 在这篇论文，作者从文本集合中提取“相关词”，以概括属于某个类别（或在unlabeled数据集下为聚类的组）的文档的内容，并在词云中可视化它们。 作者比较了三种提取相关单词的方法，并使用两个数据集验证了模型的可用性。论文链接：https://arxiv.org/pdf/1707.05261.pdf，论文代码：https://github.com/cod3licious/textcatvis\n目标 提供一个文件数据集，输出一组词云，展示最能够区分每个文件类别的词。这里的数据集可以是标注的或是未标注的，对未标注的数据集作者先进行了聚类。\n上图是作者论文中的图片，五个词云分别表示最能代表论文五个部分（Abstract, Introduction, Methods, Results, Discussion，即文件类别）的词。\n方法 数据预处理和特征提取 首先对所有文件进行1.小写化 2. 删除非字母数字的字符。然后逐段用tfidf转换为bag-of-words（BOW）特征向量\\(\\mathbf x_k \\in \\mathbf R^T \\forall k \\in {1,\\dots,N}\\)，其中\\(k\\)是文件编号，\\(T\\)是该文件包含的词汇数（vocabulary，即去重词数），\\(N\\)是文件数。表示文件\\(k\\)的特征向量里对应单词\\(t_i\\)的值\\(\\mathbf x_{ki} = tf(t_i) idf(t_i)\\)。\nTF-IDF Term Frequency-Inverse Document Frequency，词频-逆文件频率，是一种用于资讯检索与资讯探勘的常用加权技术。TF-IDF是一种统计方法，用以评估一单词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。即一个词语在一篇文件中出现次数越多, 同时在所有文档中出现次数越少, 越能够代表该文件。一般做归一化处理，公式如下：\n$$ tf(t_i)=\\frac{在某一文件中词t_i出现的次数}{该文件中所有的词数目} \\\nidf(t_i)=\\log(\\frac{数据集的文件总数}{包含词t_i的文件数})=\\log\\frac{|N|}{|{k\\in N:t_i\\in k}|} $$\n有时为了保证\\(idf\\)分母不为零，可以在分母上加一。\n未标注数据集聚类 对于未标注的数据集，首先要聚类成多个cluster，然后针对每个cluster计算相关单词。作者采用的是DBSCAN（density-based spatial clustering of applications with noise，https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf），首先把tfidf向量用线性PCA降维到250维，然后对特征做交叉，再计算向量间的距离（1 - cosine similarity）。对于聚类时使用的距离门槛（threshold），作者经过实验推荐最低cosine similarity为0.45.\n计算相关单词（relevant word） 确定相关单词分为两步，第一步是计算描述相关性的relevance score \\(r_c\\)，第二步时根据\\(r_c\\)给所有单词排序，越高代表越相关。为了计算\\(r_c\\)，作者比较了三种方法：\n 通过汇总组中所有文档的原始tf-idf特征； 通过汇总由某些分类器（SVM+LRP）加权的这些特征； 分别计算每个单词在该类和其他类出现的文件数量，进而求出\\(r_c\\)。  突出tfidf特征法（Salient tf-idf features） 最直接简单的方法，对类别\\(c\\)计算\\(r_c\\)的公式为：\n$$ r_c (t_i) = \\sum_{k:y_k=c}\\mathbf x_{ki}=\\sum_{k:y_k=c}tf_k(t_i)idf_k(t_i) $$\n即将所有属于类别\\(c\\)的文件\\(k\\)中的单词\\(t_i\\)的tf-idf值加起来作为这个类别中该单词的relevance score。这样分数最高的单词在该类别的文件中出现频率最高，且不会在大多数其他文件里出现（否则idf值会很低）。然而，一个可能的问题是，高分词在其他类别的文件中出现频率也差不多，这对idf的值影响不大，但意味着在其他类别中该词也会被判定为relevant word，这与relevant word的定义矛盾（最能用来区分不同类别的词）。\nSVM+LRP（Decomposed classifier scores） 分为两步，第一步找到一个线性分类器，利用tfidf特征将文件分类。即对类\\(c\\)，找到\\(\\mathbf w_c\\)，最优化分类器：\n$$ \\hat y_k = \\mathop{\\arg \\max}_{c} \\ b_c + \\mathbf w_c^T\\mathbf x_k $$\n优化好分类器后，计算relevance score：\n$$ r_c(t_i) = \\sum_{k:y_k=c}\\left( \\mathbf w_{ci} \\mathbf x_{ki} + \\frac{b_c}{T}\\right) $$\n其中\\(T\\)是词汇数。\n在优化分类器时，作者选择了SVM，并提出，也可以用其他的线性分类器比如逻辑回归，甚至DNN。作者强调，只有在分类器精确度相当高的时候，这个方法找出来的相关词汇才有意义，所以分类器的精确度比简便更加重要。\nLayerwise relevance propagation（LRP） 是一个计算相关性，并将相关性逐层向后传播的过程。首先将网络模型看成一个拓扑图结构，在计算一个节点 a 和输入的节点之间的相关性时，将 a 点的数值作为相关性，并且计算与 a 点相连的上一层节点在生成 a 点时所占的权重，将 a 的相关性逐层向后传播，直到输入层。作者用下图的例子告诉了我们：\n如果要计算 \\(v_1\\) 和 \\(u_1\\) 之间的相关性，首先计算 \\(v_1\\)和 \\(z_1\\), \\(z_2\\) 之间的相关性，再将 \\(v_1\\) 和\\(z_1\\), \\(z_2\\) 的相关性传递到 \\(u_1\\), 从而求得 \\(v_1\\) 和 \\(u_1\\) 之间的相关性。\nSupport vector machine （SVM，支持向量机） 是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机；SVM还包括核技巧，这使它成为实质上的非线性分类器。SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。\nSVM学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。如下图所示，\\(\\mathbf w \\mathbf x + b = 0\\)即为分离超平面，对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的。\nSVM有一个重要性质：训练完成后，大部分的训练样本都不需要保留，最终模型仅与支持向量有关。\n算法如下：\n输入：训练数据集 \\(T={(\\mathbf x_1,y_1),(\\mathbf x_2,y_2),\\dots,(\\mathbf x_n,y_n)}\\)其中，\\(\\mathbf x_i \\in \\mathbf R^n, y_i \\in {1,-1},i = 1,2,\\dots,n\\)；\n输出：分离超平面和分类决策函数\n（1）选择惩罚参数\\(C \u0026gt; 0\\) ，构造并求解凸二次规划问题\n$$ \\min_\\alpha \\frac{1}{2}\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_i\\alpha_jy_iy_j(\\mathbf x_i\\mathbf x_j) - \\sum_{i=1}^N\\alpha_i\\\ns.t.\\ \\sum_{i=1}^N\\alpha_iy_i=0\\\n0\\le \\alpha_i\\le C, i=1,2,\\dots,N $$\n得到最优解\\(\\mathbf\\alpha^=(\\alpha_1^,\\alpha_2^,\\dots,\\alpha_N^)^T\\)\n（2）计算\n$$ \\mathbf {\\omega} ^* = \\sum_{i=1}^N\\alpha_i^*y_i\\mathbf x_i $$\n选择\\(\\mathbf \\alpha^\\)的一个分量\\(\\mathbf \\alpha_j^\\)满足条件\\(0\u0026lt;\\mathbf \\alpha_j^* \u0026lt; C\\)，计算\n$$ b^* = y_j - \\sum_{i=1}^N\\alpha_i^*y_i(\\mathbf x_i\\mathbf x_j) $$\n（3）求分离超平面\n$$ \\mathbf \\omega ^* \\mathbf x + b^* = 0 $$\n分类决策函数：\n$$ f(\\mathbf x) = sign(\\mathbf\\omega^\\mathbf x +b^) $$\n词-文件数量法（Distinctive words） 作者引入了两个概念：TPR（True Positive Rate，真阳性率）和FPR（假阳性率）。定义分别为\n$$ TPR_c(t_i) = \\frac{类别为c且t_i的tfidf值大于0的文件数}{类别为c的文件数}=\\frac {|{k:y_k=c\\ \\and \\ \\mathbf x_{ki} \u0026gt; 0}|}{|{k:y_k=c}|}\\\nFPR_c(t_i) = mean({TPR_l(t_i):l\\ne c})+std({TPR_l(t_i):l\\ne c}) $$\n最终目的是找出在目标类中出现频繁（TPR高），且在非目标类中出现不频繁（FPR低）的词，需要一个度量这一性质的函数。一种直接的方法是直接算差值：\n$$ r_c_diff(t_i) = \\max {TPR_c(t_i)-FPR_c(t_i),0} $$\n这种方法存在一个问题，即只考虑了两个率的绝对差值，未考虑相对差，即如果1. TPR=0.9，FPR=0.8；2. TPR=0.2，FPR=0.1，这种量度会认为他们一样重要，但显然前者对于后者，TPR和FPR相差过近。因此引入基于除法的算法：\n$$ r_c_quot(t_i) = \\frac{\\min{\\max{z_c(t_i),1},4} -1}{3} \\\nwhere\\ z_c(t_i) = \\frac{TPR_c(t_i)}{\\max{FPR_c(t_i),\\epsilon}}, \\epsilon是一个极小值，用来避免除数为零 $$\n综合二者，得到既考虑相对又考虑绝对差异的度量：\n$$ r_c_dist(t_i) = 0.5(r_c_diff(t_i)+r_c_quot(t_i)) $$\nrc-TPR-FPR关系图：\n结论 作者用scientific publications（标记的，主题、格式分类）和New York Times article（未标记的，寻找热度主题）两个数据集验证了算法的可行性。该方法快速且可靠，更重要的是，即使许多cluster仅包含很少的样本，也有可能可以识别出relevant words，而用分类算法很难达到这个效果。\n参考 https://zhuanlan.zhihu.com/p/31886934\nhttps://www.sohu.com/a/150681957_114778\n","date":"2020-11-19T15:14:26+08:00","permalink":"http://xpgreat.com/p/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBexploring-text-datasets-by-visualizing-relevant-words/","title":"论文解读：Exploring text datasets by visualizing relevant words"},{"content":"窗口函数是对Hive的一项增强，用来更方便地分析离线数据。窗口函数的使用场景非常之多，包括去重、排名、分组求和等等。本文希望尽可能全面的归纳窗口函数的用法，以便日后的查阅。\n窗口函数 基本用法模式 \u0026lt;FUNCTION\u0026gt;(\u0026lt;params\u0026gt;) OVER (\u0026lt;window\u0026gt;), 表示对window内的元素进行function操作，这里的window可以理解为分组，例如partition by col1 order by col2 desc ，即”相同的col1分为一组，按照每一行对应的col2的值倒序排序“。function即对每一组采取的操作，比如取平均值，这样可以得到对每一个不同的col1的col2的平均值的表，即：\n该操作的hive语句：\nSELECT col1, col2, AVG(col2) over (partition by col1 order by col2 desc) FROM test_table [where ...]; Lead \u0026amp; Lag LEAD(col, n, DEFAULT): 用于统计窗口内往下第n行值。col指定列名，DEFAULT指定如果往下n行没有值了的替换值，如不指定则是NULL。\nLAG(col, n, DEFAULT): 用于统计窗口内往上第n行值。col指定列名，DEFAULT指定如果往上n行没有值了的替换值，如不指定则是NULL。\nFirstValue \u0026amp; LastValue FIRST_VALUE(col, NO_NULL): 用于统计窗口内截止到当前行的第1行值。col指定列名，NO_NULL指定是否跳过空值，默认TRUE跳过。\nLAST_VALUE(col, NO_NULL): 用于统计窗口内截止到当前行的最后一行值。col指定列名，NO_NULL指定是否跳过空值，默认TRUE跳过。\nAggregation Functions  COUNT(col)：计数 SUM(col)：求和 MIN(col)：求最小值 MAX(col)：求最大值 AVG(col)：求平均值  Ranking Functions 注意排序已经在window语句中执行了。\n ROW_NUMBER()：求该行在window中的行数，从1开始，遇到重复值的按窗口出现的顺序递增排列。常用于取前n个记录，比如取用户最近一次冒泡时间。 RANK()：求该行在window中的排名，重复值的名次相同，但会留下空位，比如两个第一后面是第三。 DENSE_RANK()：求该行在window中的排名，重复值的名次相同，不会留下空位，比如两个第一后面是第二。 CUME_RANK()：小于等于当前值的行数占比。 PERCENTILE_RANK()：(该行的RANK值-1)/(窗口总行数-1)，百分数排名。 NTILE(n)：将窗口按顺序切成n片，如果切出来的结果不均匀，分界处的行归入上一片。  窗口子句 窗口子句可以用来更精细的描述窗口，注意有几个函数是不支持窗口子句的：Rank, NTile,DenseRank,CumeDisk,PercentRank,Lead,Lag.\n   子句 意义     PRECEDING 往前   FOLLOWING 往后   CURRENT ROW 当前行   UNBOUNDED 起点（一般结合PRECEDING，FOLLOWING使用）   UNBOUNDED PRECEDING 表示该窗口最前面的行（起点）   UNBOUNDED FOLLOWING 表示该窗口最后面的行（终点）    用法实例：\nROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW：从该窗口的起点到当前行\nROWS BETWEEN 2 PRECEDING AND 1 FOLLOWING：从前2行到后1行\nROWS BETWEEN 2 PRECEDING AND 1 CURRENT ROW：从前2行到当前行\n","date":"2020-10-29T11:01:26+08:00","permalink":"http://xpgreat.com/p/hive%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%E6%80%BB%E7%BB%93/","title":"Hive窗口函数总结"},{"content":"最近在阅读François Chollet写的Deep Learning with Python. 书中有很多经验性的技巧和归纳，其中4.5写的Machine Learning的工作流程归纳的很好，看完深有启发，摘录于此。\n机器学习的标准流程可以分为六个步骤：\n 定义问题 确定衡量模型的标准 确定评估方式 建立一个比理论平均更好的简单模型 扩展模型，使其过拟合 优化模型  一般的机器学习方面的研究主要关注第6步，但最好按照标准流程来做。\n定义问题 首先思考，可用的数据有哪些，希望从这些数据中得到什么信息，希望用这些信息预测什么。需要注意预测的内容必须要从training data中能得到信息的，比如要为影评做情绪分类，必须要有影评和它对应的情绪标签作training data才行。\n考虑问题的类型：二元分类？多元分类？标量回归？向量回归？多元多标签分类？聚类？\u0026hellip;\u0026hellip;总之明确问题的类型，有助于后面选择模型。\n明确输入和输出。时刻记住在使用机器学习的时候，存在两个假设：\n 输出可以通过输入预测得到。 已有的数据足够多以提取出输入和输出的关系。  比如如果做一个模型预测股票价格的走势，在仅有历史价格数据的时候是不够的，因为历史价格不包含未来价格的信息。机器学习只能利用training data中存在的模式(pattern)。\n另外如果这个问题是不平稳的(Nonstationary)，机器学习也不适用。比如做推荐服装的模型，不同季节对不同服装的喜好程度是不同的，如果用八月的数据训练预测九月的情况，模型效果肯定很差。这时则要采取变通，比如使用多年的数据训练，添加月份标签等。\n确定衡量模型的标准 考虑清楚问题并估计可以建模之后，需要确定一个衡量标准，来判断模型是否成功。比如预测值的准确度，客户留存度，正确分类的比例等等。需要注意的是很多时候标准是根据问题自定的，这就需要建模者有经验。可以在Kaggle之类的竞赛网站上拓展视野。\n确定评估方式 确定一个评估方式来衡量进度也是很重要的。一般来说有三种方法：\n 使用一个hold-out validation set，即将数据集分出一部分专门用来验证模型效果。在有大量数据时可以使用这个方法。 K-fold Cross Validation， 将原始数据分成K组(K-Fold)，将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型。这K个模型分别在验证集中评估结果，最后的误差取平均就得到交叉验证误差。在数据量不足以做第一种方法时可以选择。但这种方法计算需求很大。 循环K-fold validation，每次都进行数据随机排列，然后进行完整的k-fold。适用于数据量很小且对精度要求高的情况。  一般选第一个即可。\n建立一个比理论平均更好的简单模型 这一步的目的是较快的找到比理论平均好的简单模型，通常可以进行简单的尝试，比如在MNIST数字分类时用最简单的feed feedforward 模型尝试，得到精确度高于0.1（完全随机分类的平均精度），这样就可以在这个基础上进行下一步的优化了。需要注意的是不是所有时候都能够找得到这样的简单模型的。如果在多次尝试后仍找不到，需要考虑是否是前面的两个假设不成立，即根本不存在输出和输入之间的明确关系，或者这种关系在已有的数据集中不明确。\n如果顺利找到这种简单模型，下一步需要考虑三个问题：\n 最后一层的激活函数。将模型网络中的倒数第二层输出组合形成最终输出，比如在二元分类时可以使用relu激活，得到一个0-1之间的数字作为选择一类的概率。 loss function，即一个可微的函数，用来衡量模型的精度。可微性是必要的因为使用梯度下降法优化时需要求微分。 优化方法，比如Adam，RmsProp等。通常可以先尝试用这两种的默认学习率（learning rate）优化。     Problem type Last-layer activation Loss function     Binary classification sigmoid binary_crossentropy   Multiclass, single-label classification softmax categorical_crossentropy   Multiclass, multilabel classification sigmoid binary_crossentropy   Regression to arbitrary values None mse   Regression to values between 0 and 1 sigmoid mse or binary_crossentropy    扩展模型 这一步将模型扩展，使其过拟合，因为上一步得到的简单模型可能没有足够的层数，没有足够多的神经元等等。机器学习问题其实就是平衡拟合能力和泛化能力的问题，我们的目标是找到二者平衡的一个点。既不能让它欠拟合，也不能让它过拟合。一般的做法是先让模型过拟合，然后再进行细节优化。扩展模型有三个方法：\n 增加层数。 增加单层神经元个数。 训练更多的epochs。  如果你发现验证的精度开始下降了，这时候就说明模型已经过拟合，这一步也可以结束了。\n优化模型 最复杂也最耗时的一步，大部分研究的重点。大致逻辑是对模型做小修小改，把数据放进去跑，看模型验证精度的变化，直到优化到不能再优化为止。一般可以尝试的方向有：\n 加入Dropout。 改变结构，比如增加或删除一层。 L1/L2正则化（Regularization）。 更改不同的超参数（hyperparameter），比如学习率、每层神经元个数等等。 增加或删除feature。  注意如果多次依据验证精度调整模型，会把验证集的信息泄露给模型（相当于验证集也参与了模型的构建和优化）。少量的次数还可以接受，太多次后会让优化后的模型没有说服力。\n当你获得一个满意的优化后的模型，可以使用所有的数据（training 和 validation set）来最后训练一次，再使用test data做最后的测试。如果最后测试结果显著不如validation的结果，则需要考虑是否overfitting，或者时评估方式（第三步）选择不对，可以尝试换一个试试。\n","date":"2020-03-15T16:25:12+08:00","permalink":"http://xpgreat.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/","title":"机器学习的工作流程"},{"content":"不记得之前安装的是什么版本，这次（2020/3）让pip自动安装选择的是2.1.0，但这个版本安装后使用import tensorflow会报错，如下：\nTraceback (most recent call last): File \u0026quot;[...]\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\u0026quot;, line 58, in \u0026lt;module\u0026gt; from tensorflow.python.pywrap_tensorflow_internal import * File \u0026quot;[...]\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u0026quot;, line 28, in \u0026lt;module\u0026gt; _pywrap_tensorflow_internal = swig_import_helper() File \u0026quot;[...]\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u0026quot;, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File \u0026quot;[...]\\lib\\imp.py\u0026quot;, line 242, in load_module return load_dynamic(name, filename, file) File \u0026quot;[...]\\lib\\imp.py\u0026quot;, line 342, in load_dynamic return _load(spec) ImportError: DLL load failed: 找不到指定的模块。 During handling of the above exception, another exception occurred: Traceback (most recent call last): File \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;[...]\\lib\\site-packages\\tensorflow\\__init__.py\u0026quot;, line 101, in \u0026lt;module\u0026gt; from tensorflow_core import * File \u0026quot;[...]\\lib\\site-packages\\tensorflow_core\\__init__.py\u0026quot;, line 40, in \u0026lt;module\u0026gt; from tensorflow.python.tools import module_util as _module_util File \u0026quot;[...]\\lib\\site-packages\\tensorflow\\__init__.py\u0026quot;, line 50, in __getattr__ module = self._load() File \u0026quot;[...]\\lib\\site-packages\\tensorflow\\__init__.py\u0026quot;, line 44, in _load module = _importlib.import_module(self.__name__) File \u0026quot;[...]\\lib\\importlib\\__init__.py\u0026quot;, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File \u0026quot;[...]\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\u0026quot;, line 49, in \u0026lt;module\u0026gt; from tensorflow.python import pywrap_tensorflow File \u0026quot;[...]\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\u0026quot;, line 74, in \u0026lt;module\u0026gt; raise ImportError(msg) ImportError: Traceback (most recent call last): File \u0026quot;[...]\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\u0026quot;, line 58, in \u0026lt;module\u0026gt; from tensorflow.python.pywrap_tensorflow_internal import * File \u0026quot;[...]\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u0026quot;, line 28, in \u0026lt;module\u0026gt; _pywrap_tensorflow_internal = swig_import_helper() File \u0026quot;[...]\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u0026quot;, line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File \u0026quot;[...]\\lib\\imp.py\u0026quot;, line 242, in load_module return load_dynamic(name, filename, file) File \u0026quot;[...]\\lib\\imp.py\u0026quot;, line 342, in load_dynamic return _load(spec) ImportError: DLL load failed: 找不到指定的模块。 报错十分奇怪，提示缺少DLL，但在网上找到的信息只有需要system32里的msvc140p.dll可能是问题所在，如果缺少可以安装Microsoft Visual C++ 2015 Redistributable解决。在检查后发现这个文件已经存在。尝试 https://blog.csdn.net/qq_42580947/article/details/104175457 上的方法后才解决。问题出在版本上，换成2.0.0正常运行。pip install tensorflow==2.0.0。另附上国内比较好用的pip源：\n  清华大学：https://pypi.tuna.tsinghua.edu.cn/simple/\n  中科大：https://pypi.mirrors.ustc.edu.cn/simple/\n  使用的时候在命令后面加上-i [源]即可。\n","date":"2020-03-15T15:22:49+08:00","permalink":"http://xpgreat.com/p/%E5%AE%89%E8%A3%85tensorflow%E6%97%B6%E8%B8%A9%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E5%9D%91/","title":"安装TensorFlow时踩的一个小坑"},{"content":"一个方便的小技巧，可以很快的安装缺失的包。\n可以使用pip或conda来安装包，注意如果环境不同包是不能通用的，在Windows下启动Anaconda Prompt的时候要注意标题后面括号内的环境是不是所需要的。\n以numpy为例，使用pip：\nimport sys !{sys.executable} -m pip install numpy 使用conda：\nimport sys !conda install --yes --prefix {sys.prefix} numpy ","date":"2019-12-09T22:01:11+01:00","permalink":"http://xpgreat.com/p/%E5%9C%A8jupyer-notebook%E9%87%8C%E5%AE%89%E8%A3%85%E5%8C%85/","title":"在Jupyer Notebook里安装包"},{"content":"在使用SSH链接远程虚拟机的时候经常会出现网络连接不稳定而导致前台运行的代码终止运行的情况，怎样能让程序稳定地在后台运行，不受断线的影响？IBM Developer上的这篇文章很有帮助，转载方便以后查阅。\n(转自Linux 技巧：让进程在后台运行更可靠的几种方法 - 申毅)\n我们经常会碰到这样的问题，用 telnet/ssh 登录了远程的 Linux 服务器，运行了一些耗时较长的任务， 结果却由于网络的不稳定导致任务中途失败。如何让命令提交后不受本地关闭终端窗口/网络断开连接的干扰呢？下面举了一些例子， 您可以针对不同的场景选择不同的方式来处理这个问题。\nnohup/setsid/\u0026amp; 场景： 如果只是临时有一个命令需要长时间运行，什么方法能最简便的保证它在后台稳定运行呢？\n解决方法： 我们知道，当用户注销（logout）或者网络断开时，终端会收到 HUP（hangup）信号从而关闭其所有子进程。因此，我们的解决办法就有两种途径：要么让进程忽略 HUP 信号，要么让进程运行在新的会话里从而成为不属于此终端的子进程。\nhangup 名称的来由\n在 Unix 的早期版本中，每个终端都会通过 modem 和系统通讯。当用户 logout 时，modem 就会挂断（hang up）电话。 同理，当 modem 断开连接时，就会给终端发送 hangup 信号来通知其关闭所有子进程。\n1. nohup nohup 无疑是我们首先想到的办法。顾名思义，nohup 的用途就是让提交的命令忽略 hangup 信号。让我们先来看一下 nohup 的帮助信息：\nNOHUP(1) User Commands NOHUP(1) NAME nohup - run a command immune to hangups, with output to a non-tty SYNOPSIS nohup COMMAND [ARG]... nohup OPTION DESCRIPTION Run COMMAND, ignoring hangup signals. --help display this help and exit --version output version information and exit 可见，nohup 的使用是十分方便的，只需在要处理的命令前加上 nohup 即可，标准输出和标准错误缺省会被重定向到 nohup.out 文件中。一般我们可在结尾加上**\u0026quot;\u0026amp;\u0026quot;**来将命令同时放入后台运行，也可用\u0026quot;\u0026gt;filename 2\u0026gt;\u0026amp;1\u0026ldquo;来更改缺省的重定向文件名。\nnohup 示例\n[root@pvcent107 ~]# nohup ping www.ibm.com \u0026amp; [1] 3059 nohup: appending output to `nohup.out' [root@pvcent107 ~]# ps -ef |grep 3059 root 3059 984 0 21:06 pts/3 00:00:00 ping www.ibm.com root 3067 984 0 21:06 pts/3 00:00:00 grep 3059 [root@pvcent107 ~]# 2. setsid nohup 无疑能通过忽略 HUP 信号来使我们的进程避免中途被中断，但如果我们换个角度思考，如果我们的进程不属于接受 HUP 信号的终端的子进程，那么自然也就不会受到 HUP 信号的影响了。setsid 就能帮助我们做到这一点。让我们先来看一下 setsid 的帮助信息：\nSETSID(8) Linux Programmer’s Manual SETSID(8) NAME setsid - run a program in a new session SYNOPSIS setsid program [ arg ... ] DESCRIPTION setsid runs a program in a new session. 可见 setsid 的使用也是非常方便的，也只需在要处理的命令前加上 setsid 即可。\nsetsid 示例\n[root@pvcent107 ~]# setsid ping www.ibm.com [root@pvcent107 ~]# ps -ef |grep www.ibm.com root 31094 1 0 07:28 ? 00:00:00 ping www.ibm.com root 31102 29217 0 07:29 pts/4 00:00:00 grep www.ibm.com [root@pvcent107 ~]# 值得注意的是，上例中我们的进程 ID(PID)为31094，而它的父 ID（PPID）为1（即为 init 进程 ID），并不是当前终端的进程 ID。请将此例与nohup 例中的父 ID 做比较。\n3. \u0026amp; 这里还有一个关于 subshell 的小技巧。我们知道，将一个或多个命名包含在“()”中就能让这些命令在子 shell 中运行中，从而扩展出很多有趣的功能，我们现在要讨论的就是其中之一。\n当我们将\u0026rdquo;\u0026amp;\u0026ldquo;也放入“()”内之后，我们就会发现所提交的作业并不在作业列表中，也就是说，是无法通过jobs来查看的。让我们来看看为什么这样就能躲过 HUP 信号的影响吧。\nsubshell 示例\n[root@pvcent107 ~]# (ping www.ibm.com \u0026amp;) [root@pvcent107 ~]# ps -ef |grep www.ibm.com root 16270 1 0 14:13 pts/4 00:00:00 ping www.ibm.com root 16278 15362 0 14:13 pts/4 00:00:00 grep www.ibm.com [root@pvcent107 ~]# 从上例中可以看出，新提交的进程的父 ID（PPID）为1（init 进程的 PID），并不是当前终端的进程 ID。因此并不属于当前终端的子进程，从而也就不会受到当前终端的 HUP 信号的影响了。\ndisown 场景： 我们已经知道，如果事先在命令前加上 nohup 或者 setsid 就可以避免 HUP 信号的影响。但是如果我们未加任何处理就已经提交了命令，该如何补救才能让它避免 HUP 信号的影响呢？\n解决方法： 这时想加 nohup 或者 setsid 已经为时已晚，只能通过作业调度和 disown 来解决这个问题了。让我们来看一下 disown 的帮助信息：\ndisown [-ar] [-h] [jobspec ...] Without options, each jobspec is removed from the table of active jobs. If the -h option is given, each jobspec is not removed from the table, but is marked so that SIGHUP is not sent to the job if the shell receives a SIGHUP. If no jobspec is present, and neither the -a nor the -r option is supplied, the current job is used. If no jobspec is supplied, the -a option means to remove or mark all jobs; the -r option without a jobspec argument restricts operation to running jobs. The return value is 0 unless a jobspec does not specify a valid job. 可以看出，我们可以用如下方式来达成我们的目的。\n 用disown -h jobspec 来使某个作业忽略HUP信号。 用disown -ah 来使所有的作业都忽略HUP信号。 用disown -rh 来使正在运行的作业忽略HUP信号。  需要注意的是，当使用过 disown 之后，会将把目标作业从作业列表中移除，我们将不能再使用jobs来查看它，但是依然能够用ps -ef查找到它。\n但是还有一个问题，这种方法的操作对象是作业，如果我们在运行命令时在结尾加了\u0026rdquo;\u0026amp;\u0026ldquo;来使它成为一个作业并在后台运行，那么就万事大吉了，我们可以通过jobs命令来得到所有作业的列表。但是如果并没有把当前命令作为作业来运行，如何才能得到它的作业号呢？答案就是用 CTRL-z（按住Ctrl键的同时按住z键）了！\nCTRL-z 的用途就是将当前进程挂起（Suspend），然后我们就可以用jobs命令来查询它的作业号，再用bg jobspec来将它放入后台并继续运行。需要注意的是，如果挂起会影响当前进程的运行结果，请慎用此方法。\ndisown 示例1（如果提交命令时已经用“\u0026amp;”将命令放入后台运行，则可以直接使用“disown”）\n[root@pvcent107 build]# cp -r testLargeFile largeFile \u0026amp; [1] 4825 [root@pvcent107 build]# jobs [1]+ Running cp -i -r testLargeFile largeFile \u0026amp; [root@pvcent107 build]# disown -h %1 [root@pvcent107 build]# ps -ef |grep largeFile root 4825 968 1 09:46 pts/4 00:00:00 cp -i -r testLargeFile largeFile root 4853 968 0 09:46 pts/4 00:00:00 grep largeFile [root@pvcent107 build]# logout disown 示例2（如果提交命令时未使用“\u0026amp;”将命令放入后台运行，可使用 CTRL-z 和“bg”将其放入后台，再使用“disown”）\n[root@pvcent107 build]# cp -r testLargeFile largeFile2 [1]+ Stopped cp -i -r testLargeFile largeFile2 [root@pvcent107 build]# bg %1 [1]+ cp -i -r testLargeFile largeFile2 \u0026amp; [root@pvcent107 build]# jobs [1]+ Running cp -i -r testLargeFile largeFile2 \u0026amp; [root@pvcent107 build]# disown -h %1 [root@pvcent107 build]# ps -ef |grep largeFile2 root 5790 5577 1 10:04 pts/3 00:00:00 cp -i -r testLargeFile largeFile2 root 5824 5577 0 10:05 pts/3 00:00:00 grep largeFile2 [root@pvcent107 build]# 灵活运用 CTRL-z 在我们的日常工作中，我们可以用 CTRL-z 来将当前进程挂起到后台暂停运行，执行一些别的操作，然后再用 fg 来将挂起的进程重新放回前台（也可用 bg 来将挂起的进程放在后台）继续运行。这样我们就可以在一个终端内灵活切换运行多个任务，这一点在调试代码时尤为有用。因为将代码编辑器挂起到后台再重新放回时，光标定位仍然停留在上次挂起时的位置，避免了重新定位的麻烦。\nscreen 场景： 我们已经知道了如何让进程免受 HUP 信号的影响，但是如果有大量这种命令需要在稳定的后台里运行，如何避免对每条命令都做这样的操作呢？\n解决方法： 此时最方便的方法就是 screen 了。简单的说，screen 提供了 ANSI/VT100 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen 的参数很多，具有很强大的功能，我们在此仅介绍其常用功能以及简要分析一下为什么使用 screen 能够避免 HUP 信号的影响。我们先看一下 screen 的帮助信息：\nSCREEN(1) SCREEN(1) NAME screen - screen manager with VT100/ANSI terminal emulation SYNOPSIS screen [ -options ] [ cmd [ args ] ] screen -r [[pid.]tty[.host]] screen -r sessionowner/[[pid.]tty[.host]] DESCRIPTION Screen is a full-screen window manager that multiplexes a physical terminal between several processes (typically interactive shells). Each virtual terminal provides the functions of a DEC VT100 terminal and, in addition, several control functions from the ISO 6429 (ECMA 48, ANSI X3.64) and ISO 2022 standards (e.g. insert/delete line and support for multiple character sets). There is a scrollback history buffer for each virtual terminal and a copy-and-paste mechanism that allows moving text regions between windows. 使用 screen 很方便，有以下几个常用选项：\n 用screen -dmS session name 来建立一个处于断开模式下的会话（并指定其会话名）。 用screen -list 来列出所有会话。 用screen -r session name 来重新连接指定会话。 用快捷键CTRL-a d 来暂时断开当前会话。  screen 示例\n[root@pvcent107 ~]# screen -dmS Urumchi [root@pvcent107 ~]# screen -list There is a screen on: 12842.Urumchi (Detached) 1 Socket in /tmp/screens/S-root. [root@pvcent107 ~]# screen -r Urumchi 当我们用“-r”连接到 screen 会话后，我们就可以在这个伪终端里面为所欲为，再也不用担心 HUP 信号会对我们的进程造成影响，也不用给每个命令前都加上“nohup”或者“setsid”了。这是为什么呢？让我来看一下下面两个例子吧。\n 未使用 screen 时新进程的进程树  [root@pvcent107 ~]# ping www.google.com \u0026amp; [1] 9499 [root@pvcent107 ~]# pstree -H 9499 init─┬─Xvnc ├─acpid ├─atd ├─2*[sendmail] ├─sshd─┬─sshd───bash───pstree │ └─sshd───bash───ping 我们可以看出，未使用 screen 时我们所处的 bash 是 sshd 的子进程，当 ssh 断开连接时，HUP 信号自然会影响到它下面的所有子进程（包括我们新建立的 ping 进程）。\n使用了 screen 后新进程的进程树  [root@pvcent107 ~]# screen -r Urumchi [root@pvcent107 ~]# ping www.ibm.com \u0026amp; [1] 9488 [root@pvcent107 ~]# pstree -H 9488 init─┬─Xvnc ├─acpid ├─atd ├─screen───bash───ping ├─2*[sendmail] 而使用了 screen 后就不同了，此时 bash 是 screen 的子进程，而 screen 是 init（PID为1）的子进程。那么当 ssh 断开连接时，HUP 信号自然不会影响到 screen 下面的子进程了。\n总结 现在几种方法已经介绍完毕，我们可以根据不同的场景来选择不同的方案。nohup/setsid 无疑是临时需要时最方便的方法，disown 能帮助我们来事后补救当前已经在运行了的作业，而 screen 则是在大批量操作时不二的选择了。\n","date":"2019-07-16T16:21:51+02:00","permalink":"http://xpgreat.com/p/%E8%AE%A9%E7%A8%8B%E5%BA%8F%E5%9C%A8%E5%90%8E%E5%8F%B0%E7%A8%B3%E5%AE%9A%E8%BF%90%E8%A1%8C%E7%9A%84%E6%96%B9%E6%B3%95/","title":"让程序在后台稳定运行的方法"},{"content":"本文介绍了公司的杠杆效应（Leverage Effect）和Modigliani-Miller定理，以阐述投资对象的资本结构与价值的无关性。\n杠杆效应 一个公司的资本结构是总资产（Total capital, T) = 股权（Equity, E）+ 债务（Debt, D）。定义：\\(r_T\\)是总资产回报率，毛利 = \\(r_T * (E+D)\\)；净利 = 毛利 - 债务利息 = \\(r_T * (E+D) - r_D * D := r_E * E\\)。则：\n$$ \\begin{aligned} r_E * E \u0026amp;= r_T * (E+D) - r_D * D \\\\r_E \u0026amp;= r_T + (r_T - r_D) * \\frac{D}{E} \\\\r_E \u0026amp;= r_T + (r_T - r_D) * DR \\end{aligned} $$\n如果\\(r_T \u0026gt; r_B\\)，\\(r_E\\)随着负债率（Debt-to-equity ratio）上升而上升。这样看来，公司应尽可能地提高负债率以提高利润率，然而这与常识似乎有矛盾。原因在于没有考虑回报率的不确定性，即他们的方差。用期望和方差的眼光来看，假设债务的利息是确定的，可以得到：\n$$ \\begin{aligned} \u0026amp;E(r_E) = E(r_T) * E+(E(r_T) - r_D) * D \\\\\u0026amp;Var(r_E) = (D+1)^2 * Var(r_T) \\end{aligned} $$\n这两个式子分别表示杠杆效应和杠杆风险（Leverage Risk）。可以看出更高负债率意味着更高的股权回报率和更高的风险，且风险升高的速度更快，这是一个用高风险换高收益的典型例子。此外，当负债率升高到足够高的时候，对债权人的风险上升，债务的利息也会上升，进一步地降低回报率。那么按照一般的想法，一定存在一个均衡点，也就是一个最好的负债率，事实如此吗？\nModigliani-Miller定理 由经济学家弗兰科·莫迪利安尼和默顿·米勒提出，它是现代资本结构理论的基础。该定理认为，在不考虑税，破产成本，信息不对称并且假设在有效市场里面，企业价值不会因为企业融资方式（资本结构）改变而改变。也即是说，不论公司选择发行股票或者卖债券，或是采用不同的红利政策，都不会影响企业价值。因此莫迪尼亚尼-米勒定理也被称为资本结构无关原理。\n假设一个投资人投资了一个公司\\(\\alpha\\)的股份，\\(\\widetilde{R}\\)表示未扣除利息的公司收益，\\(r * D\\)表示确定的需要公司支付的债务利息（假定利率等于市场无风险利率）。此时投资人的收入为\\(\\alpha (\\widetilde R - r * D)\\)，投资头寸为\\(\\alpha * E_M\\)（\\(E_M\\)是公司股权的市值。）\n这个投资人有自己的偏好，他更想投资一个零负债的公司，他打算出售一部分的股票投资到无风险项目中，假设新的投资比例为\\(\\beta\\)，出售股票回流\\((\\alpha - \\beta) * E_M\\)。此时投资人的收入为：来自投资公司\\(\\beta (\\widetilde R - r * D)\\)，来自无风险投资\\(r(\\alpha - \\beta)E_M\\)，投资头寸分别为\\(\\beta * E_M\\)和\\((\\alpha - \\beta) * E_M\\)。\n当\\(\\beta\\)为多少的时候，投资人的收入和投资一个无负债公司的收入是一样的？当投资人要承担的公司债务利息部分与投资人无风险投资的利息相等的时候：\n$$ \\begin{aligned} \\beta * r * D \u0026amp;= r(\\alpha - \\beta)E_M \\\\\\beta * r * DR * E_M \u0026amp;= r(\\alpha - \\beta)E_M \\\\\\beta * DR \u0026amp;= \\alpha - \\beta \\\\\\beta \u0026amp;= \\frac{\\alpha}{1+DR} \\end{aligned} $$\n即投资人把投资比例调至\\(\\frac{\\alpha}{1+DR}\\)时，等价于投资了一个零负债的公司。所以，公司的负债比例与投资人能否按自己偏好进行投资没有关系，因为可以用这种方法创建完全符合投资人的投资组合。\n","date":"2019-06-08T11:23:53+02:00","permalink":"http://xpgreat.com/p/%E6%8A%95%E8%B5%84%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%B5%84%E6%9C%AC%E7%BB%93%E6%9E%84%E6%97%A0%E5%85%B3%E6%80%A7/","title":"投资对象的资本结构无关性"},{"content":"从1981年的智利电力体制改革之后，英美等国先后进行了电力工业重组，这些努力导致了电力工业的市场化，促成了电力市场的形成，实现了资源的合理分配和社会效益的最大化。准确的电力价格对发电商、用户、监管者具有重要的意义。本文将常用的电价预测（EPF, Electricity Price Forecasting）模型进行了分类，并加以简介。\n本文主要参考了’Rafał Weron, Electricity price forecasting: A review of the state-of-the-art with a look into the future, International Journal of Forecasting, Volume 30, Issue 4, 2014, Pages 1030-1081, ISSN 0169-2070‘ 写成博文以整理思路。\n电力市场模式简介 首先简单介绍一下电力市场的运作模式。电力市场主要由三方构成：供应商、用户、管理者。供应商负责发电，用户买电用电，管理者维护市场秩序。由于电力是一种很特别的商品，它无法大规模储存，只能即发即用，很容易造成某一时刻的供给和需求不平衡，这种不平衡反应到价格上面，所以电价极不稳定。早期的电力市场是高度管制的，管理机构制定发电量、电价等等，十分稳定，但效率很差，浪费资源，也不利于电力市场的发展。市场化（自由化）后的电力市场引入竞争，很多供应商参与竞价，提高效率促进发展。目前市场化的电力市场基本分为两种模式，日前（Day-ahead）市场和日内（Intraday）市场。日前市场中供应商在前一天向清算机构报告自己的供应量和价格，在某一个时间点（比如18:00）清算机构整合所有供应商的信息，确定下一天的电价，一般是以小时为单位。日内市场与股票市场类似，通常是供应商提前一段时间竞价，比如12:00的时候竞价12:15-12:30的电价，一般以15分钟为单位。日内市场相较日前市场而言更加的不稳定。\n电价预测的分类 可以分为长期、中期、短期预测。但它们之间尚没有明确的界限。长期一般研究几个月、一个季度到几年的范围，一般用于决定投资、长期协议和其他战略行动。中期一般研究几个星期到一个月的范围，主要用于资源分配、报表分析、风险管理、金融计算等。短期一般研究几分钟到几个星期的范围，用于降低生产成本、提高发电厂利润等。中短期预测使用的方法基本类似，与长期预测的不同。本文只介绍中短期的模型，长期预测日后再写。\n中短期电价预测的六个类型 中短期电价预测模型众多，大体可以分为六个类型：Multi-agent, Fundamental, Reduced-form, Statistical, Computational intelligence 以及它们的组合。\n Multi-agent模型运用经济学、博弈论等学科知识，模拟电力市场的各方行为，匹配供给和需求预测价格。 Fundamental模型通过模拟重要物理和经济因素对电价的影响来描述价格动态变化。 Reduced-form模型描述电价随时间推移的统计特性，最终目标是金融衍生工具的评估和风险管理。 Statistical模型直接运用统计学和计量经济学的方法根据前期数据进行预测。 Computational intelligence模型运用机器学习结合了学习、进化、模糊化的特性，可以灵活的适应复杂的动态模型。 组合模型在上述模型中进行组合，目标是结合各模型的优势，弱化劣势，取长补短。  下面详细介绍前五类模型，包括该类型的优势劣势以及例子，重点是Computational intelligence模型。\nMulti-agent模型 预测电价在过去是一项直接但困难的任务。它通常涉及中期和长期时间范围，并涉及将需求预测与供给相匹配，供给是通过依运营成本排列计划生产量得到的。这些基于成本的模型（Production-cost model，PCM）能够以一小时一小时的速度预测价格。然而，他们忽略了战略招标策略，包括市场的力量。它们适用于受监管的市场，价格不确定性很小、结构稳定、没有博弈的情况，但不适合竞争激烈的电力市场。均衡（Equilibrium）（博弈论）方法可被视为PCM的一般化方法，并结合战略投标策略进行修正。这些模型对于预测没有价格历史，但已知供应成本和市场集中度的市场的价格水平特别有用。另一方面，越来越流行的基于agent的仿真技术可以解决静态均衡模型忽略的电力市场特征。\nNash-Cournot framework，均衡方法的一种。在Nash-Cournot框架中，电力被视为同质商品，市场均衡通过供应商的容量设定来确定。但是这些模型预测的价格往往高于现实中的价格。\nSupply function equilibrium，将价格建模为公司投标与供给（和需求）曲线的均衡。 计算供给函数均衡（SFE）需要求解一组微分方程，而不是Nash-Cournot框架中出现的典型代数方程组。 因此，这些模型在其数字易处理性方面具有相当大的限制。\nStrategic production-cost models，是传统生产成本模型（PCM）的衍生。 战略PCM（SPCM）将代理商（agent）的出价策略也考虑在内。 每个agent都试图最大化自己的利润，同时考虑其成本结构和竞争对手的预期行为，通过战略参数建模，该参数代表每个供应商生产水平的剩余需求函数的斜率。与前两个模型相比，SPCM的计算效率很高，这让它可用于实时的价格分析。\nAgent-based simulation models，是一类计算结构和规则，用于模拟自主代理（无论是个人还是集体实体，如组织或团体）的行为和交互，最终目标是评估它们对整个系统的影响。\n这类模型极其灵活，但这种灵活要求模型使用者自己确定很多变量，比如参与者是谁，他们可能用的策略是什么，他们互相交互的方式等。另外，multi-agent模型更多地关注的是质量问题而不是定量结果，比如他们可以预测价格是否高于边际成本，以及这个是否会影响参与者的收益；但是如果要求得到更定量的结论，比如高精度的预测价格，这类模型会产生问题。\nFundamental模型 试图捕捉电力生产和交易中存在的基本物理量和经济指标的关系。 假设基本因素（负载，天气条件，系统参数等）之间的功能相互关联，并且通常通过Statistical，Reduced-form或Computational Intelligence独立地对基本输入进行建模和预测。 此外，文献中考虑的许多EPF方法是基于时间序列、回归和神经网络模型的混合解决方案，其使用一些Fundamental的因素 - 例如负载，燃料价格，风力或温度 - 作为输入变量。主要分为两个子类：parameter rich models 和 parsimonious structural models。\nParameter-rich fundamental models，通常被开发为专有的内部产品，因此，它们的细节不会公开披露。 公布的大部分结果都与水电主导电力市场有关。顾名思义，此类模型运用很多输入参数，Vahviläinen and Pyykkönen (2005) 提出了一个模型，使用了27个标量参数（13个气候参数、4个需求和10个供给参数），并使用了29个公式来描述参数之间的关系。\nParsimonious structural models是parameter-rich模型的简化，可以追溯到Barlow (2002)提出的由对市场供给和需求曲线的实证研究得出的现货价格过程，运用了Box–Cox transformation的逆。\n这类模型面对的挑战主要有两点，第一是数据难以获得，根据市场的不同，关于工厂容量、成本、需求模式和运输能力等数据不一定可以供研究人员建模使用。第二是在建模的时候应用一些关于市场的假设，所以数据的随机性变化会对模型的可信度产生较大影响。另外由于这类模型使用的数据一般是在较长时间范围内获取的，所以更适合用于中期预测而不是短期价格预测。所以在应用这类模型的时候存在着很多风险。\nReduced-form模型 金融风格的Reduced-form（定量，随机）价格动态模型的一个共同特征是，它们的主要目的不是提供准确的每小时的价格预测，而是复制每日电价的主要特征，如未来时间点的边际分布、价格动态以及商品价格之间的相关性。这些模型是衍生品定价和风险管理系统的核心。如果选择的价格过程不适合描述电价的主要属性，则模型的结果可能不可靠。同时，如果模型过于复杂，计算负担将阻止其在交易部门中的使用（Weron，2006）。\nJump-diffusion models Markov regime-switching models\n通常此类模型不会准确地预测每小时价格，但可以发现电力现货价格的主要特征，通常是在每日的时间尺度下。这些模型简化但合理地描述了价格动态，并且通常用于衍生品定价和风险分析（参见Benth et al.，2008; Eydeland＆Wolyniec，2003）。 有趣的是，当涉及到波动性或价格飙升的预测时，简化模型的表现相当不错。\nStatistical模型 统计模型运用数学方法组合过去的电价数据和/或外部数据，一般是生产数据、需求数据、天气数据。一般分为两类：加法模型和乘法模型。加法模型把各个参数加起来，乘法模型则是乘起来，这两种模型可以相互转换，比如对乘法模型求对数。统计模型最大的优势在于它很好解释变量的影响，方便理解模型内部的行为。然而统计模型也因为它不好支持非线性拟合而受到批评。\nSimilar-day使用和预测当天相似的那天的数据来预测，它可以使用比如需求量、天气等数据来判断两天的相似程度。 可以使用指数平滑（exponential smoothing methods）来提高精确度，但这种模型在与其他模型比较中精确度不是很理想。\n回归模型是使用最广泛的一种，很好理解，这里不做过多描述。值得一提的是在建模的时候很多人使用小波变换（wavelet），可以提高精确度。\nAR-MA类型的时间序列分析模型，基本的时间序列分析模型。这种模型对于平稳的时间序列数据的表现比较好，所以产生了差分ARMA（又称ARIMA，AutoRegressive Integrated Moving Average）模型，它将数据（n阶）差分化，即把\\(X_t\\)变化成\\(X_t - X_{t-1}\\)以获取平稳的时间序列（一阶差分）。另外的还可以做季节差分（SARIMA，seasonal ARIMA）等。\nARX类型的时间序列分析模型，X代表eXgenous，即输入外部数据的AR模型，因为电价也受很多外源因素的影响。由此衍生了ARX, ARMAX, ARIMAX, SARIMAX等模型。\nThreshold autoregressive models (TAR), SETAR(Self Exciting TAR), STAR(Smooth Transition AR), LSTAR(Logistic STAR), TARX(TAR eXgenous)等等。\nHeteroskedasticity and GARCH-type models，异方差性和GARCH类模型。包括AutoRegressive Conditional Heteroskedastic (ARCH), Generalized ARCH (GARCH), (S)AR(IMA)-GARCH等等。\n统计型模型的精确度不仅取决于模型的选取、算法的使用，也取决于获取的数据的质量。对于处理价格激增，统计模型的效果不是很好，尤其是对于只是用价格作为数据的模型，对于价格spike的识别可以用以下方法：recursive filters (Cartea \u0026amp; Figueroa, 2005; Weron, 2008), variable price thresholds (Trück, Weron, \u0026amp; Wolff, 2007), fixed price change thresholds (Bierbrauer et al., 2004)（不推荐，因为忽视了长期和季节性变化）, regime-switching classification (RSC;Janczura et al., 2013), and wavelet filtering (Stevenson, 2001;Weron, 2006)。\nComputational intelligence models CI（有的文献中也称AI）模型是受自然事物启发产生的计算方法，结合了学习、进化、模糊化的元素，可以灵活的适应复杂的动态模型，解决传统模型不能解决的问题。\nCI模型的分类 每一个的CI模型都可以根据它的架构和学习算法分类，架构表示神经元的连接方式，学习算法表示模型怎样根据训练数据调整优化它的各项权重。在EPF的背景下，它也可以依据输出向量的维度分类，输出一维或多维。一维的一般用于预测下一小时电价 (e.g. Gonzalez, San Roque, \u0026amp; Garcia-Gonzalez, 2005; Mandal, Senjyu, \u0026amp; Funabashi, 2006)，h小时后电价 (e.g. Amjady, 2006; Hu et al., 2008; Rodriguez \u0026amp; Anders, 2004)等等。多维的一般用于一次性预测接下来几个小时的电价，不如前者常见(e.g. Yamin, Shahidehpour, \u0026amp; Li, 2004)。根据神经元的拓扑结构可以分为两类，前馈网络（feed-forward networks）和递归网络（recurrent networks），前者不含循环而后者有。前馈网络更多的被用于预测价格而递归网络往往被用于分类(Jain, Mao, \u0026amp; Mohiuddin, 1996; Rutkowski, 2008)。\n此外CI模型还可以被用于区间预测（interval forecasting，与置信区间confidence interval有区别），在这里不展开说了。\n前馈神经网络 最简单的前馈神经网络只包含一个输入层，一个输出层，中间由一个感知神经元连接，它等价于一个线性回归的模型。通过增加中间神经元（隐藏层）的层数和个数，可以做到拟合非线性的关系（MLP, Multi Layer Perceptron）。每个神经元里都有一个激活函数，可以将输入进行一些处理，常用的有ReLU，tanh，softmax等等。在激活函数中可以使用径向基函数（Raidal Basis Function），构成一类特殊的模型。径向基通常使用高斯核函数（Gaussian Kernel）。\n简单的MLP和RBF模型通常被当作测试对比模型，真正应用的模型大多是他们与其他模型的混合模型，比如Shafie-Khah et al. (2011) 提出了一个 wavelet-ARIMA-RBF模型，结合了小波变换、ARIMA和RBF的优缺点。研究指出，RBF更适合研究局部数据的特点，MLP适合描述整体的数据趋势。\n递归神经网络 详见另一篇博文：递归神经网络\n前馈神经网络存在一个问题，它不能描述相邻两个数据之间的关系，RRN则可以很好的解决这一点，前面cell的输出是后面cell的输入，或者有一个贯穿整个模型的状态记忆量。\n模糊神经网络 模糊逻辑是通常的布尔逻辑的推广，因为它的输入值可以不止为0或1，还可以是某些定性范围。例如，温度可以是低，中或高。模糊逻辑允许从模糊或噪声的输入推导出输出，重要的是，不需要指定输入到输出的精确映射。模糊神经网络则是应用了模糊逻辑推广的神经网络，一般还要使用一个去模糊化函数以获取精确结果。\n支持向量机 向量机的讲解推荐支持向量机通俗导论（理解SVM的三层境界）。\n与ANN不同，SVM通过把数据非线性投影到高维度，再对投影后的数据使用简单的线性函数以拟合数据的非线性关系，而ANN是通过复杂的函数来拟合非线性关系。SVM的一个优点是它得出的是全局的最值，而不是ANN给出的局部最值（因为一般使用梯度下降优化）。\n优势和劣势 主要的优势是可以拟合复杂的、非线性的关系，因此它通常比纯统计学的模型效果要更好一些。但同时它不太灵活，这是它的主要缺陷。另外，CI模型种类繁多，存在很多变种，而且不同模型间难以比较（参数、输入数据等经常不同），参数、激活函数选择众多，所以很难选择一个最好的模型。\n后记 电价预测是一个涉及广泛的研究领域，永远都无法找到一个最令人满意的预测方法，数据精度、模型调参、模型间的组合多种多样······不管是预测什么东西都是这样，也正是因为其中存在的不确定性和创造性，这个领域才如此的有吸引力。\n","date":"2019-05-25T17:35:01+02:00","permalink":"http://xpgreat.com/p/%E4%B8%AD%E7%9F%AD%E6%9C%9F%E7%94%B5%E4%BB%B7%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B/","title":"中短期电价预测模型简介"},{"content":"递归神经网络是神经网络的一种，与其他神经网络不同点在于，它可以很好地处理序列数据，即前面的数据的输入与后面的输出是有关系的，比如一句话的语义理解。本文介绍了递归神经网络及其两个变种——LSTM和GRU，目的是梳理一下自己所理解的RRN，也希望能够给初次接触RRN的同学一点帮助。\n其他神经网络的不足——为什么需要RRN？ 传统神经网络的结构大多为输入-隐藏层（多个）-输出，即给定一组输入数据，输出结果，隐藏层像一个黑盒子，通过各种运算把输入的数据算成需要的结果。输入不同的数据运行两次，它们的结果是完全无关的。而有的时候我们需要处理一个序列，比如一个句子，它是单词的序列，要理解这句话中各个单词的意思，必须要结合语境，也就是要结合其他的单词的意思，一般情况下要结合这个单词前面的单词。例如前面两个词是我、吃，那么后面的一个词很大概率是一个表示食物的名词。\n为了解决一些这样类似的问题，能够更好的处理序列的信息，RNN就诞生了。\nRNN的结构 循环神经网络也由输入层、隐藏层和输出层构成，这是神经网络的基本结构，不同的是它的隐藏层（也叫cell）可以连续的接收输入\\(x\\)，输出\\(o\\)，而贯穿其中的\\(s\\)可以存储这个网络的状态，也就是“记忆”到的前面发生的事情，利用它可以更加精准的预测后面的输出。\n一个最简单的RNN结构如图所示，每一个cell输入一个\\(x\\)和一个\\(s\\)，输出两个同样的\\(h\\)，通过下列算法算出：\n$$ \\begin{aligned} \u0026amp;s_t = \\tanh (Ws_{t-1} + Ux_t) \\\\\u0026amp;h_t = Vs_t \\end{aligned} $$\n这种简单的结构虽然可以达到记忆的效果，然而存在着一个致命的问题：梯度爆炸和梯度消失。即在多次循环后，利用梯度下降法调整，在求导的时候会出现\\(\\frac{\\partial Loss}{\\partial w_i} = \\frac{\\partial Loss}{\\partial f_t}\\frac{\\partial f_t}{\\partial f_{t-1}}\u0026hellip;\\frac{\\partial f_i}{\\partial w_i} \\)，如果\\(\\frac{\\partial f_t}{\\partial f_{t-1}}\\)部分大于或小于1，会出现类似1.01的99次方（或0.99的99次方）的问题，使得权重过大或过小，无法使用梯度下降。这一问题的根源就在于\\(W\\)和\\(s\\)之间的乘法运算。为了解决这一问题，Hochreiter, Schmidhuber（1997)提出了LSTM。\nLSTM LSTM全称Long Short Time Memory RRN，长短期记忆循环神经网络，它本质上也是一个循环神经网络，只是cell不一样而已，如下图： LSTM的关键之处在于cell的状态，也就是图中贯穿顶部的那条水平线。Cell的状态像是一条传送带，它贯穿整条链，其中只发生一些小的线性作用。信息流过这条线而不改变是非常容易的。但是，LSTM也有能力移除或增加信息到cell状态中，由被称为门的结构精细控制。门是一种让信息可选地通过的方法。它们由一个sigmoid(\\( S(t)={\\frac {1}{1+e^{-t}}}\\))神经网络层和一个点乘操作组成。这里的sigmoid函数取0-1的值，充当了开关的作用，控制影响的程度。\n运行过程 从左往右看这幅图，首先第一步是决定我们需要从cell状态中扔掉什么样的信息。这个决策由一个称为“遗忘门（forget gate）”的sigmoid层决定。输入 \\(h_{t-1}\\) 和 \\(x_t\\) ，输出一个0和1之间的数。1代表“完全保留这个值”，而0代表“完全扔掉这个值”。比如对于一个基于上文预测最后一个词的语言模型。cell的状态可能包含当前主题的信息，来预测下一个准确的词。而当我们得到一个新的语言主题的时候，我们会想要遗忘旧的主题的记忆，应用新的语言主题的信息来预测准确的词。\n第二步是决定我们需要在cell state里存储什么样的信息。这个问题有两个部分。第一，一个sigmoid层调用“输入门（input gate）”以决定哪些数据是需要更新的。然后，一个\\(tanh\\)层为新的候选值创建一个向量 \\(\\tilde{C}_t\\) ，这些值能够加入state中。下一步，我们要将这两个部分合并以创建对state的更新。\n比如还是语言模型，可以表示为想要把新的语言主题的信息加入到cell state中，以替代我们要遗忘的旧的记忆信息。\n在决定需要遗忘和需要加入的记忆之后，就可以更新旧的cell state \\(C_{t-1}\\) 到新的cell state \\(C_t\\) 了。在这一步，我们把旧的state \\(C_{t-1}\\) 与 \\(f_t\\) 相乘，遗忘我们先前决定遗忘的东西，然后我们加上 \\(i_t * \\tilde{C}_t\\) ，这可以理解为新的记忆信息，当然，这里体现了对状态值的更新度是有限制的，我们可以把 \\(i_t\\) 当成一个权重。\n最后，我们需要决定要输出的东西。这个输出基于我们的cell state，但会是一个过滤后的值。首先，我们运行一个sigmoid层，这个也就是输出门（output gate），以决定cell state中的那个部分是我们将要输出的。然后我们把cell state放进\\(tanh\\)（将数值压到-1和1之间），最后将它与sigmoid门的输出相乘，这样我们就只输出了我们想要的部分了。\n在LSTM中，状态\\(S\\)通过累加的方式来计算，\\(S_t = \\sum_{\\tau=1}^t \\Delta S_{\\tau}\\)，这样就不会是一直复合函数的形式了，它的导数也不是乘积的形式，这样就不会发生梯度消失的情况了。（具体论文：An Empirical Exploration of Recurrent Network Architectures 和 Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling）\nGRU GRU全称Gated Recurrent Unit，循环门单元。和LSTM一样，他也只是个cell的种类，本质上是RNN，由 Cho, et al. (2014)提出。它将LSTM的遗忘门和输入门组合成了一个新的更新门，合并了cell state和hidden state，比LSTM更加简单（尽管稍微难理解一些）。\n从左往右看，前两个门是reset gate和update gate，计算方法：\n$$ \\begin{aligned} \u0026amp;r_t = \\sigma (W^rx_t + U^rh_{t-1}) \\\\\u0026amp;z_t = \\sigma (W^zx_t + U^zh_{t-1}) \\end{aligned} $$\nreset gate控制在计算候选状态时使用多少前序的状态，update gate则表示计算新状态时候选状态和原状态各取多少比例（注意特殊的“1-”门，表示把\\(z_t\\)当作一个比例）。\n总结和比较 RRN是神经网络的一个种类，LSTM和GRU是两种特殊的cell。与最基本的cell结构相比，LSTM和GRU都很好的解决了梯度爆炸和梯度消失的问题。对比LSTM，GRU的参数更少，因而训练稍快或需要更少的数据来泛化。另一方面，如果有足够的数据，LSTM的强大表达能力可能会产生更好的结果。Greff, et al. (2015)对流行的变种做了一个很好的比较，发现它们都是一样的。Jozefowicz, et al.(2015)测试了超过一万中RNN结构，发现某些任务情形下，有些比LSTM工作得更好，但那也是比较特殊的时候。\n总的来说，没有通用的最好的模型，只能通过具体的数据和问题来选择模型。如果研究的数据序列会相互影响，比如做词语预测，那么LSTM-RRN和GRU-RRN不失为一种很好的选择。\n参考：\n 深入理解lstm及其变种gru Understanding LSTM Networks ","date":"2019-05-14T10:48:15+02:00","permalink":"http://xpgreat.com/p/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","title":"递归神经网络"},{"content":"最近终于开始写毕业论文了，要求用英语，从网上搜集了一下英语论文的句型，整理后发布到博客，方便查阅。\n链接  Thesis Statements from UNC 如何提高英文的科研写作能力 如何开始写英文论文？ - 李忆非的回答 - 知乎 如何开始写英文论文？ - 肉山大猫王的回答 - 知乎 English Report Template  Beginning  In this paper, we focus on the need for This paper proceeds as follow. The structure of the paper is as follows. In this paper, we shall first briefly introduce fuzzy sets and related concepts To begin with we will provide a brief background on the  Introduction  This will be followed by a description of the fuzzy nature of the problem and a detailed presentation of how the required membership functions are defined. Details on xx and xx are discussed in later sections. In the next section, after a statement of the basic problem, various situations involving possibility knowledge are investigated: first, an entirely possibility model is proposed; then the cases of a fuzzy service time with stochastic arrivals and non fuzzy service rule is studied; lastly, fuzzy service rule are considered.  Review  This review is followed by an introduction. A brief summary of some of the relevant concepts in xxx and xxx is presented in Section 2. In the next section, a brief review of the \u0026hellip;. is given. In the next section, a short review of \u0026hellip; is given with special regard to \u0026hellip; Section 2 reviews relevant research related to xx. Section 1.1 briefly surveys the motivation for a methodology of action, while 1.2 looks at the difficulties posed by the complexity of systems and outlines the need for development of possibility methods.  Body  Section 1 defines the notion of robustness, and argues for its importance. Section 1 devoted to the basic aspects of the FLC decision making logic. Section 2 gives the background of the problem which includes xxx Section 2 discusses some problems with and approaches to, natural language understanding. Section 2 explains how flexibility which often \u0026hellip; can be expressed in terms of fuzzy time window Section 3 discusses the aspects of fuzzy set theory that are used in the \u0026hellip; Section 3 describes the system itself in a general way, including the ….. and also discusses how to evaluate system performance. Section 3 describes a new measure of xx. Section 3 demonstrates the use of fuzzy possibility theory in the analysis of xx. Section 3 is a fine description of fuzzy formulation of human decision. Section 3, is developed to the modeling and processing of fuzzy decision rules The main idea of the FLC is described in Section 3 while Section 4 describes the xx strategies. Section 3 and 4 show experimental studies for verifying the proposed model. Section 4 discusses a previous fuzzy set based approach to cost variance investigation. Section 4 gives a specific example of xxx. Section 4 is the experimental study to make a fuzzy model of memory process. Section 4 contains a discussion of the implication of the results of Section 2 and 3. Section 4 applies this fuzzy measure to the analysis of xx and illustrate its use on experimental data. Section 5 presents the primary results of the paper: a fuzzy set model .. Section 5 contains some conclusions plus some ideas for further work. Section 6 illustrates the model with an example. Various ways of justification and the reasons for their choice are discussed very briefly in Section 2. In Section 2 are presented the block diagram expression of a whole model of human DM system In Section 2 we shall list a collection of basic assumptions which a \u0026hellip; scheme must satisfy. In Section 2 of this paper, we present representation and uniqueness theorems for the fundamental measurement of fuzziness when the domain of discourse is order dense. In Section 3, we describe the preliminary results of an empirical study currently in progress to verify the measurement model and to construct membership functions. In Section 5 is analyzed the inference process through the two kinds of inference experiments\u0026hellip; This Section In this section, the characteristics and environment under which MRP is designed are described. We will provide in this section basic terminologies and notations which are necessary for the understanding of subsequent results.Next Section The next section describes the mathematics that goes into the computer implementation of such fuzzy logic statements. However, it is cumbersome for this purpose and in practical applications the formulae were rearranged and simplified as discussed in the next section. The three components will be described in the next two section, and an example of xx analysis of a computer information system will then illustrate their use. We can interpret the results of Experiments I and II as in the following sections. The next section summarizes the method in a from that is useful for arguments based on xx  Summary  This paper concludes with a discussion of future research consideration in section 5. Section 5 summarizes the results of this investigation. Section 5 gives the conclusions and future directions of research. Section 7 provides a summary and a discussion of some extensions of the paper. Finally, conclusions and future work are summarized The basic questions posed above are then discussed and conclusions are drawn. Section 7 is the conclusion of the paper.  Chapter 0. Abstract  A basic problem in the design of xx is presented by the choice of a xx rate for the measurement of experimental variables. This paper examines a new measure of xx in xx based on fuzzy mathematics which overcomes the difficulties found in other xx measures. This paper describes a system for the analysis of the xx. The method involves the construction of xx from fuzzy relations. The procedure is useful in analyzing how groups reach a decision. The technique used is to employ a newly developed and versatile xx algorithm. The usefulness of xx is also considered. A brief methodology used in xx is discussed. The analysis is useful in xx and xx problem. A model is developed for a xx analysis using fuzzy matrices. Algorithms to combine these estimates and produce a xx are presented and justified. The use of the method is discussed and an example is given. Results of an experimental applications of this xx analysis procedure are given to illustrate the proposed technique. This paper analyses problems in This paper outlines the functions carried out by \u0026hellip; This paper includes an illustration of the \u0026hellip; This paper provides an overview and information useful for approaching Emphasis is placed on the construction of a criterion function by which the xx in achieving a hierarchical system of objectives are evaluated. The main emphasis is placed on the problem of xx Our proposed model is verified through experimental study. The experimental results reveal interesting examples of fuzzy phases of: xx, xx The compatibility of a project in terms of cost, and xx are likewise represented by linguistic variables. A didactic example is included to illustrate the computational procedure  Chapter 1. Introduction Time  Over the course of the past 30 years, .. has emerged form intuitive Technological revolutions have recently hit the industrial world The advent of \u0026hellip; systems for has had a significant impact on the The development of \u0026hellip; is explored During the past decade, the theory of fuzzy sets has developed in a variety of directions The concept of xx was investigated quite intensively in recent years There has been a turning point in \u0026hellip; methodology in accordance with the advent of \u0026hellip; A major concern in \u0026hellip; today is to continue to improve\u0026hellip; A xx is a latecomer in the part representation arena. At the time of this writing, there is still no standard way of xx Although a lot of effort is being spent on improving these weaknesses, the efficient and effective method has yet to be developed. The pioneer work can be traced to xx [1965]. To date, none of the methods developed is perfect and all are far from ready to be used in commercial systems.  Objective / Goal / Purpose  The purpose of the inference engine can be outlined as follows: The ultimate goal of the xx system is to allow the non experts to utilize the existing knowledge in the area of manual handling of loads, and to provide intelligent, computer aided instruction for xxx. The paper concerns the development of a xx The scope of this research lies in The main theme of the paper is the application of rule based decision making. These objectives are to be met with such thoroughness and confidence as to permit \u0026hellip; The objectives of the \u0026hellip; operations study are as follows: The primary purpose/consideration/objective of The ultimate goal of this concept is to provide The main objective of such a \u0026hellip; system is to The aim of this paper is to provide methods to construct such probability distribution. In order to achieve these objectives, an xx must meet the following requirements: In order to take advantage of their similarity more research is still required before final goal of \u0026hellip; can be completed In this trial, the objective is to generate\u0026hellip; for the sake of concentrating on \u0026hellip; research issues A major goal of this report is to extend the utilization of a recently developed procedure for the xx. For an illustrative purpose, four well known OR problems are studied in presence of fuzzy data: xx. A major thrust of the paper is to discuss approaches and strategies for structuring ..methods This illustration points out the need to specify The ultimate goal is both descriptive and prescriptive.  Chapter 2. Literature Review A wealth of information is to be found in the statistics literature, for example, regarding xx A considerable amount of research has been done .. during the last decade A great number of studies report on the treatment of uncertainties associated with xx. There is considerable amount of literature on planning However, these studies do not provide much attention to uncertainty in xx. Since then, the subject has been extensively explored and it is still under investigation as well in methodological aspects as in concrete applications. Many research studies have been carried out on this topic. Problem of xx draws recently more and more attention of system analysis. Attempts to resolve this dilemma have resulted in the development of Many complex processes unfortunately, do not yield to this design procedure and have, therefore, not yet been automated. Most of the methods developed so far are deterministic and /or probabilistic in nature. The central issue in all these studies is to The problem of xx has been studied by other investigators, however, these studies have been based upon classical statistical approaches. Applied \u0026hellip; techniques to Characterized the \u0026hellip; system as Developed an algorithm to Developed a system called \u0026hellip; which Uses an iterative algorithm to deduce Emphasized the need to Identifies six key issues surrounding high technology A comprehensive study of the\u0026hellip; has been undertaken Much work has been reported recently in these filed Proposed/Presented/State that/Described/Illustrated/ Indicated/Has shown / showed/Address/Highlights Point out that the problem of A study on \u0026hellip;was done / developed by [] Previous work, such as [] and [], deal only with The approach taken by [] is The system developed by [] consists A paper relevant to this research was published by [] []\u0026rsquo;s model requires consideration of\u0026hellip; []' model draws attention to evolution in human development []\u0026rsquo;s model focuses on\u0026hellip; Little research has been conducted in applying \u0026hellip; to The published information that is relevant to this research\u0026hellip; This study further shows that Their work is based on the principle of More history of \u0026hellip; can be found in xx et al. [1979]. Studies have been completed to established The \u0026hellip;studies indicated that Though application of xx in the filed of xx has proliferated in recent years, effort in analyzing xx, especially xx, is lacking. Problem / Issue / Question Unfortunately, real-world engineering problems such as manufacturing planning do not fit well with this narrowly defined model. They tend to span broad activities and require consideration of multiple aspects. Remedy / solve / alleviate these problems \u0026hellip; is a difficult problem, yet to be adequately resolved Two major problems have yet to be addressed An unanswered question This problem in essence involves using x to obtain a solution. An additional research issue to be tackled is \u0026hellip;. Some important issues in developing a \u0026hellip; system are discussed The three prime issues can be summarized: The situation leads to the problem of how to determine the \u0026hellip; There have been many attempts to It is expected to be serious barrier to It offers a simple solution in a limited domain for a complex ","date":"2019-05-08T22:13:27+02:00","permalink":"http://xpgreat.com/p/%E8%8B%B1%E6%96%87%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E5%8F%A5%E5%9E%8B/","title":"英文论文写作句型"},{"content":"在学习机器学习的算法时，推导过程中往往会涉及矩阵或向量求导以及一些其他的线性代数的知识。比如在推导LDA算法的时候，就是把Fisher\u0026rsquo;s Criterion求导后置零得到的结果。另外在优化的时候经常会使用到梯度下降法，这与矩阵向量求导也是分不开的。\n记号 在这篇文章中，向量统一为列向量，用\\(\\mathbf x\\)表示，矩阵用\\(X\\)大写字母表示，标量用\\(x\\)表示。求导使用\\(\\frac{\\partial f(\\mathbf x)}{\\partial \\mathbf x}\\)表示。\n线性代数的一些变换 $$ \\begin{aligned} \u0026amp;1.\\ (AB)^{-1} = B^{-1}A^{-1}\\\\ \u0026amp;2.\\ (A^T)^{-1} = (A^{-1})^T\\\\ \u0026amp;3.\\ AB = C \\Leftrightarrow DAB = DC\\\\ \u0026amp;4.\\ \\left[ \\begin{matrix} a \u0026amp; b\\\\ c \u0026amp; d \\end{matrix} \\right]^{-1} = \\frac{1}{ad-bc}\\left[ \\begin{matrix} d \u0026amp; -b\\\\ -c \u0026amp; a \\end{matrix} \\right] \\\\ \u0026amp;5.\\ (A+B)^T = A^T + B^T\\\\ \u0026amp;6.\\ (AB)^T = B^TA^T \\\\ \u0026amp;7.\\ A = A^{\\frac{1}{2}}A^{\\frac{1}{2}} \\\\ \u0026amp;8.\\ A^0 = I \\end{aligned} $$\n正交矩阵 正交矩阵（orthogonal matrix）是一个方块矩阵，其元素为实数，而且行与列皆为正交的单位向量，使得该矩阵的转置矩阵为其逆矩阵：\\(S^{-1} = S^T\\)。比如恒等变换：\n$$ \\left[ \\begin{matrix} 1 \u0026amp; 0\\\\ 0 \u0026amp; 1 \\end{matrix} \\right] $$\n和旋转\\(\\alpha \\)：\n$$ \\left[ \\begin{matrix} \\cos \\alpha \u0026amp; -\\sin \\alpha \\\\ \\sin \\alpha \u0026amp; \\cos \\alpha \\end{matrix} \\right] $$\nEigenvalue（特征值） 若\n$$ A\\mathbf u = \\lambda \\mathbf u $$\n则\\(\\lambda\\)是特征值，\\(\\mathbf u\\)是其对应的特征向量。\n由此可以推出特征值分解，即对于对称矩阵\\(A\\)，可以被分解为：\n$$ A = U \\Lambda U^T $$\n其中\\(U\\)是正交矩阵，它的列是\\(A\\)的特征向量，\\(\\Lambda\\)是对角矩阵，是对应的\\(A\\)的特征值。\n变量多次出现的求导方法 若在函数表达式中，某个变量出现了多次，可以单独计算函数对自变量的每一次出现的导数，再把结果加起来。\n举例（该规则对向量和矩阵也是成立的，这里先用标量举一个简单的例子）：假设函数表达式是\\(f(x)=(2x+1)x+x^2\\)，可以先把三个\\(x\\)看成三个不同的变量，即把\\(f\\)的表达式看成\\((2x_1+1)x_2+x_3^2\\)，然后分别计算\\(\\partial f / \\partial x_1 = 2x_2\\),\\(\\partial f / \\partial x_2 = 2x_1 + 1\\)，和\\(\\partial f / \\partial x_3 = 2x_3\\)，最后总的导数就是这三项加起来：\\(2x_2 + 2x_1 + 1 + 2x_3\\)，此时再把\\(x\\)的下标抹掉并化简，就得到\\(6x+1\\)。熟悉这个过程之后，可以省掉添加下标再移除的过程。\n这个方法和多层神经网络算法中的反向传递（Back Propagation）的思想方法是一样的。\n最常用的四个矩阵向量求导公式 $$ \\begin{aligned} \u0026amp;1.\\ \\frac{\\partial A\\mathbf x}{\\partial \\mathbf x} = A \\\\ \u0026amp;2.\\ \\frac{\\partial \\mathbf x^T \\mathbf a}{\\partial \\mathbf x} = \\frac{\\partial \\mathbf a^T \\mathbf x}{\\partial \\mathbf x} = \\mathbf a \\\\ \u0026amp;3.\\ \\frac{\\partial \\mathbf ||x||^2}{\\partial \\mathbf x} = \\frac{\\partial \\mathbf x^T \\mathbf x}{\\partial \\mathbf x} = 2 \\mathbf x \\\\ \u0026amp;4.\\ \\frac{\\partial \\mathbf x^T A \\mathbf x}{\\partial \\mathbf x} = (A + A^T)\\mathbf x \\end{aligned} $$\n推导过程 最基础的出发点是，对矩阵或者向量求导，就是对其中的每一个元素关于每一个自变量中的元素进行求导，最后写成一个矩阵的形式，所以落脚点在单个元素上。\n公式1 容易看出\\(A\\mathbf x\\)是一个向量，对其中一个元素进行求导，注意下标，求和符号内只有一项包含\\(x_k\\)，其他的可以直接舍弃：\n$$ \\begin{aligned} \\frac{\\partial}{\\partial x_k} (A\\mathbf x)_{i} \u0026amp;= \\frac{\\partial}{\\partial x_k} \\sum_{j=1}^{n} A_{ij}x_j \\\\ \u0026amp;= A_{ik} \\end{aligned} $$\n所以可得在求导结果矩阵中每一行每一列的元素都等于\\(A\\)在这个位置上的元素，q.e.d.\n公式2 \\(\\mathbf x^T \\mathbf a\\)和\\(\\mathbf a^T \\mathbf x\\)都是标量。证明过程和1相似：\n$$ \\frac{\\partial}{\\partial x_i} \\mathbf x^T \\mathbf a = \\frac{\\partial}{\\partial x_i} \\sum_{j=1}^{n} x_ja_j = a_i \\\\ \\frac{\\partial}{\\partial x_i} \\mathbf a^T \\mathbf x = \\frac{\\partial}{\\partial x_i} \\sum_{j=1}^{n} a_jx_j = a_i $$\n这个公式是最基本的，但极其重要和常用。\n公式3 证明过程也十分简单：\n$$ \\frac{\\partial \\mathbf ||x||^2}{\\partial x_i} = \\frac{\\partial}{\\partial x_i} \\sum_j x_j^2 = \\frac{\\partial}{\\partial x_i} x_i^2 = 2x_i $$\n公式4 可以看出结果是一个标量。应用前面所说的变量多次出现的求导方法，先把后面的\\(A \\mathbf x\\)看成整体，对前一个\\(\\mathbf x\\)求导，运用公式2，可得：\n$$ \\frac{\\partial \\mathbf x^T (A \\mathbf x')}{\\partial \\mathbf x} = A \\mathbf x' $$\n类似的对后面的\\(\\mathbf x\\)求导，可得：\n$$ \\frac{\\partial (\\mathbf x'^T A) \\mathbf x}{\\partial \\mathbf x} = (\\mathbf x'^T A)^T = A^T\\mathbf x' $$\n去掉一撇，加起来，可得：\n$$ \\frac{\\partial \\mathbf x^T A \\mathbf x}{\\partial \\mathbf x} = A \\mathbf x + A^T\\mathbf x = (A + A^T)\\mathbf x $$\nq.e.d.\n应用举例 LDA算法的推导过程中需要解\\(\\mathbf w\\)：\n$$ \\underset{\\mathbf w}{\\operatorname{argmax}} \\frac{\\mathbf w^TS_B\\mathbf w}{\\mathbf w^TS_W\\mathbf w} $$\n其中\\(S_B\\)和\\(S_W\\)都是对称矩阵。容易发现分式上下都是标量。要求最大值，对\\(\\mathbf w\\)求导，置零即可。先运用商的导数公式：\n$$ \\frac{\\partial}{\\partial \\mathbf w}\\frac{\\mathbf w^TS_B\\mathbf w}{\\mathbf w^TS_W\\mathbf w} = \\frac{\\mathbf w^TS_W\\mathbf w(\\frac{\\partial}{\\partial \\mathbf w}\\mathbf w^TS_B\\mathbf w) - \\mathbf w^TS_B\\mathbf w(\\frac{\\partial}{\\partial \\mathbf w}\\mathbf w^TS_W\\mathbf w)}{(\\mathbf w^TS_W\\mathbf w)^2} $$\n求分子上的导数，运用上面的公式4：\n$$ \\frac{\\partial}{\\partial \\mathbf w}\\mathbf w^TS_B\\mathbf w = (S_B + S_B^T)\\mathbf w $$\n由于\\(S_B\\)是对称的，\\(S_B^T = S_B\\),\n$$ \\frac{\\partial}{\\partial \\mathbf w}\\mathbf w^TS_B\\mathbf w = 2S_B\\mathbf w $$\n对另一个倒数类似，置零可得：\n$$ \\frac{(\\mathbf w^TS_W\\mathbf w)2S_B\\mathbf w - (\\mathbf w^TS_B\\mathbf w)2S_W\\mathbf w}{(\\mathbf w^TS_W\\mathbf w)^2} \\overset{!}{=} 0 $$\n即：\n$$ \\begin{aligned} (\\mathbf w^TS_B\\mathbf w)2S_W\\mathbf w \u0026amp;= (\\mathbf w^TS_W\\mathbf w)2S_B\\mathbf w \\\\ S_W\\mathbf w \u0026amp;= \\frac{\\mathbf w^TS_W\\mathbf w}{\\mathbf w^TS_B\\mathbf w}S_B\\mathbf w \\\\ S_W\\mathbf w \u0026amp;= S_B\\mathbf w \\lambda \\\\ \\mathbf w \u0026amp;= S_W^{-1} S_B\\mathbf w \\lambda \\end{aligned} $$\n另请参阅  Matrix Cookbook，很好的一本公式集，适合查阅。 Mathematics for Machine Learning 机器学习中的矩阵、向量求导 ","date":"2019-01-17T21:47:14+01:00","permalink":"http://xpgreat.com/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC/","title":"机器学习中的矩阵求导"},{"content":"记录一些在使用MathJax写公式时踩过的坑，持续更新。本来放在另一篇里的，内容越来越多，单独成篇。\n用$ $无法输入行内公式 MathJax默认禁用了这种方式，你可以使用\\\\( 你的公式 \\\\)的方法，也可以参考它的default.js自行配置（在295行）。行间公式默认可以用\\\\[ 你的公式 \\\\]或者传统的TeX写法$$ 你的公式 $$。\n输入下标出错 x_{abc}这样使用的时候会莫名其妙的报错，试了一下把_转义：x\\_{abc}，就能用了。\n公式不能换行 因为md解析的时候把\\\\解析成了一个\\，解决方法是用四根\\\\\\\\ 换行（最后要加一个半角空格）。（也是醉了）\n公式对齐 直接上代码：\n\\begin{aligned} \u0026amp;\\nabla_{\\mathbf x}A\\mathbf x = A \\\\\\\\ \u0026amp;\\frac{\\partial \\mathbf x^T \\mathbf a}{\\partial \\mathbf x} = \\frac{\\partial \\mathbf a^T \\mathbf x}{\\partial \\mathbf x} = \\mathbf a \\\\\\\\ \\end{aligned} 效果： $$ \\begin{aligned} \u0026amp;\\nabla_{\\mathbf x}A\\mathbf x = A \\\\ \u0026amp;\\frac{\\partial \\mathbf x^T \\mathbf a}{\\partial \\mathbf x} = \\frac{\\partial \\mathbf a^T \\mathbf x}{\\partial \\mathbf x} = \\mathbf a \\\\ \\end{aligned} $$\n自定义运算名，比如argmax \\\\underset{\\mathbf w}{\\operatorname{argmax}} \\frac{\\mathbf w^TS_B\\mathbf w}{\\mathbf w^TS_B\\mathbf w} 效果：\n$$ \\underset{\\mathbf w}{\\operatorname{argmax}} \\frac{\\mathbf w^TS_B\\mathbf w}{\\mathbf w^TS_B\\mathbf w} $$\n","date":"2019-01-17T17:28:35+01:00","permalink":"http://xpgreat.com/p/%E4%BD%BF%E7%94%A8mathjax%E6%97%B6%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","title":"使用MathJax时的注意事项"},{"content":"在认知算法课里学习了一些算法，比如NCC，感知算法，LDA等等，小结一下。\nNearest Centroid Classifier NCC. 最简单的一个归类算法。输入多个\\((\\mathbf x, y)\\)，其中\\(\\mathbf x\\)表示特征，\\(y\\)表示所属类别，比如\\( y \\in \\{ -1,1 \\} \\)。将每一类的\\(\\mathbf x\\)取平均，得到一个向量，称为原型（Prototype）。预测一个新的\\(\\mathbf x\\)是属于哪一类的时候，计算并比较它与每一类的原型的相似度（距离），归为最相似的那一类中。比如\\(y = -1： (0, 1); y = 1: (1, 0)\\)，输入\\(\\mathbf x = (0, 2)\\)，计算它与\\((0, 1)\\)和\\((1, 0)\\)的距离并比较，容易得出离前者更近，所以归入\\(y = -1\\)组。\n基于这一思想，可以推导出一个函数\\(f(\\mathbf x)\\)，当\\(\\mathbf x\\)属于一个组的时候函数值为正，属于另一个组的时候函数值为负。略去推导过程，给出结果：\n$$ f(\\mathbf x) = {\\mathbf w}^T \\mathbf x - \\beta $$\n其中：\n$$ {\\mathbf w} = \\mathbf w_{-1} - \\mathbf w_{+1} \\\\ \\beta = \\frac{1}{2} \\left( \\mathbf w_{-1}^T \\mathbf w_{-1} - \\mathbf w_{+1}^T \\mathbf w_{+1} \\right) $$\n感知算法 和NCC类似，输入一组数据和他们的类别，输出一个\\(\\mathbf w\\)。\n引入一个概念感知错误（Perceptron Error），衡量一个\\(\\mathbf w\\)的好坏。定义为：\n$$ E_p(\\mathbf w) = - \\sum_{m \\in M} \\mathbf w^T \\mathbf x_m y_m $$\n其中\\(M\\)是所有分类错误的数据的index。为了获得一个最优的\\(\\mathbf w\\)，将上面的\\(E_p(\\mathbf w)\\)最小化即可。在这里使用了随机梯度下降法（Stochastic Gradient Descent）。\n$$ \\mathbf w^{new} = \\mathbf w^{old} - \\eta \\nabla E_p(\\mathbf w^{old}) = \\mathbf w^{old} + \\eta \\mathbf x_m y_m $$\n其中最初的\\(\\mathbf w\\)可以随机取得，\\(\\eta\\)是学习率（learning rate），反应变化的速率，由于梯度下降法的特点，\\(\\eta\\)不能太大也不能太小，太大可能得不出结果，太小的话会收敛太慢。\n使用这个方法时，可以设定一个跳出条件，比如相邻两次的变化量小于某个值，让模型重复随机取值、计算即可。\nLinear Discriminant Analysis LDA，线性判别分析，是后续很多算法的基础，十分重要。和前面两个算法的目的一样，为了找出\\(\\mathbf w\\)和\\(\\beta\\)。\n引入一个概念，费希尔标准（Fisher Criterion），用来衡量两个类别的分离程度：\n$$ F = \\frac{between \\ class \\ variance}{within \\ class \\ variance} = \\frac{({\\mathbf w_{+1} - \\mathbf w_{-1}})^2}{\\sigma_{+1}^2 + \\sigma_{-1}^2} $$\n其中：\n$$ \\mathbf w_i = \\frac{1}{N_i}\\sum_{j=1}^{N_i}\\mathbf x_{ji}, \\\\ \\sigma_i^2 = \\frac{1}{N_i} \\sum_{j=1}^{N_i}(x_{ji} - \\mathbf w_i)^2 $$\n为了找到最优的\\((\\mathbf w , \\beta)\\)组合，只需要最大化组间variance，最小化组内variance即可，即最大化\\(F\\)。求导、推导过程略过，计算方法如下：\n首先用上面的方法计算\\(\\mathbf w_i\\)。\n计算组内方差矩阵：\n$$ S_W = \\frac{1}{N_{-}} \\sum_{i \\in y_{-}} (\\mathbf x_i - \\mathbf w_{-}) (\\mathbf x_i - \\mathbf w_{-})^T + \\frac{1}{N_{+}} \\sum_{i \\in y_{+}} (\\mathbf x_i - \\mathbf w_{+}) (\\mathbf x_i - \\mathbf w_{+})^T $$\n算出结果：\n$$ \\mathbf w = S_W^{-1}(\\mathbf w_{+} - \\mathbf w_{-}) \\\\ \\beta = \\frac{1}{2} \\mathbf w^T (\\mathbf w_{+} + \\mathbf w_{-}) + \\log (\\frac{N_{-}}{N_{+}}) $$\nOrdinary Least Squares OLS，普通最小二乘法，用于线性回归。输入一组数据\\((\\mathbf x, y)\\)，得到线性函数\\(f(\\mathbf x) = \\mathbf \\omega^T \\mathbf x\\)，把其中的\\(\\mathbf x\\)替换为合适的核函数（Kernel Function）\\(\\mathbf \\phi (\\mathbf x)\\)可以用于非线性回归。\n引入概念最小二乘误差（Least Square Error），用于衡量线性函数与样本的契合度：\n$$ E(\\mathbf \\omega) = \\sum_{t=1}^T (y_t - \\mathbf \\omega^T \\mathbf x_t)^2 $$\n求导，置零，推导过程略过，得到结果为：\n$$ \\mathbf \\omega = (\\mathbf X \\mathbf X^T)^{-1}\\mathbf X y^T $$\n可以把\\(y\\)扩展到多维，这样得到的是Linear Mapping。\n很多时候时候线性函数\\(f(\\mathbf x) = \\mathbf \\omega^T \\mathbf x\\)不满足需求，需要添加一个偏移量，也就是把函数变成\\(f(\\mathbf x) = \\mathbf \\omega^T \\mathbf x + bias\\)，可以通过在样本\\(\\mathbf X\\)的最上方加入一行\\(1\\)来实现。\nRidge Regression 有时候仅仅使用OLS会导致过拟合(Overfitting)的问题，即模型使用过多的参数过度适应样本而不能反应真实情况，所以控制\\(\\mathbf \\omega\\)的复杂度是有必要的。\n扩展一下最小二乘误差：\n$$ E_{RR} (\\mathbf \\omega) = (y - \\mathbf \\omega^T \\mathbf X)^2 + \\lambda \\mathbf \\omega^2 $$\n其中\\(\\lambda\\)被称为Ridge，控制它的大小以控制\\(\\mathbf \\omega\\)的复杂度，不能太大也不能太小，太大会导致欠拟合，太小会导致过拟合。\n推导过程略过，得到的结果为：\n$$ \\mathbf \\omega = (\\mathbf X \\mathbf X^T + \\lambda \\mathbf I)^{-1}\\mathbf X y^T $$\n结语 以上差不多是这门课里学到的全部算法，主要用于线性归类和回归，可以使用适当的核函数（Kernel Function）扩展到非线性的范围。另外还可以使用Cross Validation来判断一个模型的好坏。关于这两个话题之后再做总结。\n","date":"2018-12-28T20:57:51+01:00","permalink":"http://xpgreat.com/p/%E8%AE%A4%E7%9F%A5%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/","title":"认知算法小结"},{"content":"利率期权(interest-rate option)是一项关于利率变化的权利。买方支付一定金额的期权费后，就可以获得这项权利：在到期日按预先约定的利率，按一定的期限借入或贷出一定金额的货币。这样当市场利率向不利方向变化时，买方可固定其利率水平；当市场利率向有利方向变化时，买方可获得利率变化的好处。利率期权的卖方向买方收取期权费，同时承担相应的责任。\nput \u0026amp; call put：约定在到期日买方有按预定利率贷出一定金额的货币的权利，如果到期日利率下跌，买方可以获得到期日利率和预定利率之间的差值作为获利；如果到期日利率上涨，高于预定利率，这时行权则不值得，不会行权。\ncall：约定在到期日买方有按预定利率借入一定金额的货币的权利，如果到期日利率上涨，买方可以获得到期日利率和预定利率之间的差值作为获利；如果到期日利率下跌，低于预定利率，这时行权则不值得，不会行权。\n利率封顶（Interest Rate Cap） 又称利率上限。客户同银行达成一项协议，指定某一种市场参考利率，同时确定一个利率上限水平。在此基础之上，利率封顶的卖出方向买入方承诺：在规定的期限内，如果市场参考利率（一般参考LIBOR(伦敦同业拆借利率),美国的联邦基金利率(Federal Funds Rate)）高于协定的利率上限水平，卖方向买方支付市场利率高于利率上限的差额部分；如果市场参考利率低于或等于协定的利率上限水平，则卖方无任何支付义务。买方由于获得了上述权利，必须向卖方支付一定数额的期权费。\n例子：发行一份浮动利率票据（Floating Rate Note, FRN），购入一份利率call。到期时市场参考利率如果低于预定利率，call不执行，利率是浮动的；如果市场参考利率高于预定利率，执行call，call的获利与市场参考利率上升的部分对冲，以达到将利率封顶的目的。\n可以用于控制利率上升的风险，比如某公司现有金额为美元1000万，期限6个月，以LIBOR计息的浮动债务，公司既希望在市场利率降低时能享有低利率的好处，又想避免市场利率上涨时利息成本增加的风险。这时，公司支付一定的期权费，向银行买入6个月，协定利率为5%的利率封顶。6个月后，如果LIBOR上升为6%（利率大于等于5%），公司选择行使该期权，即银行向公司支付市场利率和协议利率的差价（6%-5%=1%），公司有效地固定了其债务利息；如果LIBOR利率低于5%，公司可选择不实施该权利，而以较低的市场利率支付债务利息。这样，对于买方，有效地控制了利率上升的风险，而卖方则收取一笔期权费。\n利率封顶的期权费与利率上限水平和协议期限有关。相对而言，利率上限水平越高，期权费率越低；期限越短，期权费率也越低。\n利率封底 （Interest Rate Floor） 又称利率下限，与利率封顶相反，利率封底是客户与银行达成一项协议，指定某一种市场参考利率，同时确定一个利率下限水平。在此基础之上，利率封底的卖出方向买入方承诺：在规定的期限内，如果市场参考利率低于协定的利率下限水平，卖方向买方支付市场利率低于利率下限的差额部分；如果市场参考利率高于或等于协定的利率下限水平，则卖方无任何支付义务。买方由于获得了上述权利，必须向卖方支付一定数额的期权手续费。\n例子：购入一份浮动利率票据，购入一份利率put。到期时市场参考利率如果高于预定利率，put不执行，利率是浮动的；如果市场参考利率低于预定利率，执行put，put的获利与市场参考利率低于预期的部分对冲，以达到将利率封底的目的。\n利率两头封（Interest Rate Collar） 又称利率上下限，是将利率封顶和利率封底两种金融工具合成的产品。具体地说，购买一项利率两头封，就是在买进一项Cap的同时，卖出一项Floor，以收入的期权费来部分抵销需要支出的期权费，达到既规避利率风险又降低费用成本的目的（自筹资金，self-financing）。卖出一项利率两头封，则是指在卖出一项Cap的同时，买入一项Floor。若Cap和Floor的预定利率相同，可以完全消除市场利率变化的影响，然而也没有获利空间，所以没有意义。Cap和Floor的预定利率不同时，可以在一定范围内从市场利率的浮动获利。当借款人预计市场利率会上涨时，可以考虑购买一项利率两头封。\n","date":"2018-12-25T11:02:13+01:00","permalink":"http://xpgreat.com/p/%E5%88%A9%E7%8E%87%E6%9C%9F%E6%9D%83/","title":"利率期权"},{"content":"期权的风险指标通常用希腊字母来表示，包括：Delta值(\\(\\Delta\\))、Gamma值(\\(\\Gamma\\))、Omega值(\\(\\Omega\\))、Theta值(\\(\\theta\\))、Vega值、Rho(\\(\\rho\\))值等。\n结合布莱克-舒尔斯期权定价模型的公式来看：\n$$ c=SN(d_1)-Xe^{-r(T-t)}N(d_2) $$\n其中，\n$$ d_1 = \\frac{\\ln \\frac{S}{X} + (r+\\frac{\\sigma^2}{2})(T-t)}{\\sigma \\sqrt{T-t}} $$ $$ d_2 = \\frac{\\ln \\frac{S}{X} + (r-\\frac{\\sigma^2}{2})(T-t)}{\\sigma \\sqrt{T-t}} $$\n\\(N(x)\\)是标准正态分布变量的累计概率分布函数。\nDelta(\\(\\Delta\\)) 又称对冲值，是衡量标的资产价格变动时，期权价格的变化幅度。\n$$ \\Delta = \\frac{dc}{dS} $$\n特性：\n 买权的Delta一定要是正值，因为期货价格上涨（下跌），期权价格随之上涨（下跌），二者始终保持同向变化。 卖权的Delta一定要是负值，因为看跌期权价格的变化与期货价格相反。 Delta的范围介乎-1到1之间。  运用：\n 衡量头寸风险：如看涨期权的Delta为0.4，意味着期货价格每变动一元，期权的价格则变动0.4元。Delta具有可加性，如果投资者持有以下投资组合：     持仓头寸 Delta 数量（张）     买入小麦期货 1 1   买入看涨期权 0.47 2   买入看跌期权 -0.53 3    该交易者的总体持仓的Delta值为\\(1+20.47-30.53=0.35\\)，也就是说这是一个偏多的头寸，相当于0.35手期货多头。\n Delta中性套期保值（Delta Hedging）：如果投资者希望对冲期权或期货头寸的风险，Delta就是套期保值比率。只要使头寸的整体 Delta值保持为0，就建立了一个中性的套期策略。  Gamma(\\(\\Gamma\\)) 反映期货价格对Delta值的影响程度。如某一期权的Delta为0.6，Gamma值为0.05，则表示期货价格上升1元，所引起Delta增加量为0.05。Delta将从0.6增加到0.65。\n$$ \\Gamma = \\frac{d\\Delta}{dS} $$\n特性：\n Gamma值均为正值，因为若期货价格上涨，看涨期权的Delta值由0向1移动，看跌期权的Delta值从-1向0移动，即期权的Delta值从小到大移动，Gamma值为正。 Gamma值越大，Delta值变化越快。 平值期权的Gamma值最大。 随着到期日的临近，平值期权Gamma值会急剧增加。  应用：\n进行Delta中性套期保值，Gamma绝对值越大的头寸，风险程度也越高，因为进行中性对冲需要调整的频率高；相反，Gamma绝对值越小的头寸，风险程度越低。对期权的买方来说，风险有限，所以Gamma值越高，Delta越不稳定，对投资者越有利。\nOmega(\\(\\Omega\\)) 又称期权价格的无风险利率粘性，表示期权价格变动量和期货价格变动量的比值。\n$$ \\Omega = \\frac{\\frac{dc}{c}}{\\frac{dS}{S}} $$\nRho(\\(\\rho\\)) 表示期权价格对无风险利率变化的敏感程度。\n$$ \\rho = \\frac{dc}{dr} $$\nTheta(\\(\\theta\\)) 表示时间变化对期权价格的影响。衡量期权的时间价值的折损的速度。\n$$ \\theta = - \\frac{dc}{dT} $$\n特性：\nTheta为负值，意味着期权的价格随着时间流逝会越来越低，折损的速度则可由Theta来衡量。例如还有60天到期的平价期权的Theta为-0.0002126，这意味着每天期权价值失去0.0002126美元。\nVega 表示期货价格的波动率变化对期权价格的影响。\n$$ Vega = \\frac{dc}{d\\sigma} $$\n特性：\nVega为正值，意味着期权的价格随着波动率的增加而增加。当期权处于平价状态时，Vega值最大；当期权处于较深的价内或者价外时，Vega值接近于零。（相关：价内权证）\n","date":"2018-12-24T17:06:00+01:00","permalink":"http://xpgreat.com/p/%E6%9C%9F%E6%9D%83%E7%9A%84%E9%A3%8E%E9%99%A9%E6%8C%87%E6%A0%87/","title":"期权的风险指标"},{"content":"Linux下压缩解压缩命令的归纳。\n.tar 解包：tar xvf FileName.tar\n打包：tar cvf FileName.tar DirName\n（注：tar是打包，不是压缩！）\n.gz 解压1：gunzip FileName.gz\n解压2：gzip -d FileName.gz\n压缩：gzip FileName\n.tar.gz 和 .tgz 解压：tar zxvf FileName.tar.gz\n压缩：tar zcvf FileName.tar.gz DirName\n.bz2 解压1：bzip2 -d FileName.bz2\n解压2：bunzip2 FileName.bz2\n压缩：bzip2 -z FileName\n.tar.bz2 解压：tar jxvf FileName.tar.bz2\n压缩：tar jcvf FileName.tar.bz2 DirName\n.bz 解压1：bzip2 -d FileName.bz\n解压2：bunzip2 FileName.bz\n压缩：未知\n.tar.bz 解压：tar jxvf FileName.tar.bz\n压缩：未知\n.Z 解压：uncompress FileName.Z\n压缩：compress FileName\n.tar.Z 解压：tar Zxvf FileName.tar.Z\n压缩：tar Zcvf FileName.tar.Z DirName\n.zip 解压：unzip FileName.zip\n压缩：zip FileName.zip DirName\n.rar 解压：rar x FileName.rar\n压缩：rar a FileName.rar DirName\n.lha 解压：lha -e FileName.lha\n压缩：lha -a FileName.lha FileName\n.rpm 解包：rpm2cpio FileName.rpm | cpio -div\n.deb 解包：ar p FileName.deb data.tar.gz | tar zxf -\n用sEx 解压：sEx x FileName.*\n压缩：sEx a FileName.* FileName\n","date":"2018-12-16T13:30:23+01:00","permalink":"http://xpgreat.com/p/linux%E4%B8%8B%E5%8E%8B%E7%BC%A9%E5%91%BD%E4%BB%A4/","title":"Linux下压缩命令"},{"content":"在Risikomanagement课上讲到了布莱克-舒尔斯期权定价模型（Black-Scholes Option Pricing Model），但只是给出了公式，没有推导。在网上查找之后终于大致弄懂，把推导过程尽可能的详细的写一写。\n简介 布莱克-舒尔斯模型（英语：Black-Scholes Model），简称BS模型，又称布莱克-舒尔斯-墨顿模型（Black–Scholes–Merton model），是一种为期权或权证等金融衍生工具定价的数学模型，由美国经济学家迈伦·舒尔斯与费雪·布莱克首先提出，并由罗伯特·C·墨顿修改模型于有派发股利时亦可使用而更完善。由此模型可以推导出布莱克-舒尔斯公式，并由此公式估算出欧式期权的理论价格。此公式问世后带来了期权市场的繁荣。该公式被广泛使用，虽然在很多情况下被使用者进行一定的改动和修正。很多经验测试表明这个公式足够贴近市场价格，然而也有会出现差异的时候，如著名的“波动率的微笑”。\n该模型就是以迈伦·舒尔斯和费雪·布莱克命名的。1997年迈伦·舒尔斯和罗伯特·墨顿凭借该模型获得诺贝尔经济学奖。然而它假设价格的变动，会符合高斯分布（即俗称的钟形曲线），但在财务市场上经常出现符合统计学肥尾现象的事件，这影响此公式的有效性。（摘自维基百科）\n效率市场假说 1965年法玛（Fama）提出，认为投资者都试图利用可获得的信息获得更多报酬；证券价格对新的市场信息的反应应该是迅速且准确的，证券价格可以反应全部信息。证券价格在市场竞争下从一个均衡水平过渡到另一个均衡水平，而与新信息对应的价格变动是相互独立的。\n效率市场假说可以分为三类：\n 弱式：目前股票价格已充分反映了过去股票价格所提供的各项情报。所以，投资人无法再运用各种方法对过去股票价格进行分析，再利用分析结果来预测未来股票价格，基于随机游走假说，未来消息是随机而来的。意即投资者无法再利用过去资讯来获得高额报酬。所以，弱势效率越高，若以过去价量为基础的技术分析来进行预测效果将会十分不准确。 半强式：目前股票价格已充分反应了所有公开资讯，所以，投资者无法利用情报分析结果来进行股票价格预测而获取高额报酬。因此，半强式效率越高，依赖公开的财务报表、经济情况及政治情势来进行基本面分析，然后再预测股票价格是徒劳无功。 强式：目前股票价格充分反应了所有已公开和未公开之所有情报。虽然情报未公开，但投资者能利用各种管道来获得资讯，所以，所谓未公开的消息，实际上是已公开的资讯且已反应于股票价格上。此种情形下，投资者也无法因拥有某些股票内幕消息而获取高额报酬。  区分点在于投资者可利用的信息对预测价格有没有用。此假说发布后，许多学者进行了实证分析，发现发达国家的证券市场大致符合弱式效率市场。\n随机过程 随机过程是指某变量的值以某种不确定的方式随时间变化的过程。根据变量是否连续和时间是否连续分为4种：连续变量在连续时间的随机过程、连续变量在离散时间的随机过程、离散变量在连续时间的随机过程，和离散变量在离散时间的随机过程。严格来说，证券价格的变化应该属于离散变量在离散时间的随机过程，然而在时间间隔很小的时候，我们可以近似的把它看作连续变量在连续时间的随机过程。\n马尔可夫过程 随机过程，在这个过程中只有变量的当前值才与其将来值有关系，过去的值与未来的预测无关。\n布朗运动 又称维纳过程。由英国的植物学家罗伯特·布朗发现并命名，维纳（Wiener）给出的其随机过程的定义。\n标准布朗运动 设\\(\\Delta t\\)代表一个小的时间间隔长度，\\(\\Delta z\\)代表变量\\(z\\)在\\(\\Delta t\\)时间内的变化，遵循标准布朗运动的\\(\\Delta z\\)具有两个特征：\n特征1：\\(\\Delta z\\)和\\(\\Delta t\\)的关系满足：\n$$ \\Delta z = \\varepsilon \\sqrt{\\Delta t} $$\n其中\\(\\varepsilon \\sim N(0,1)\\)。\n特征2：对于任何两个不同时间，\\(\\Delta z\\)和\\(\\Delta t\\)相互独立。因此标准布朗运动是一个特殊的马尔可夫过程。\n考虑在一段时间\\(T\\)内\\(z\\)的变化：\n$$ z(T) - z(0) = \\sum^N_{i=1} \\varepsilon_i \\sqrt{\\Delta t} $$\n当\\(\\Delta t \\to 0\\)时，可以得到极限的布朗运动：\n$$ dz = \\varepsilon \\sqrt{dt} $$\n普通布朗运动 引入两个概念：漂移率（Drift Rate），表示单位时间内\\(z\\)均值的变化值；方差率（Variance Rate），表示单位时间内的方差。令漂移率的期望为\\(a\\)，方差率的期望为\\(b^2\\)，可以得到变量\\(x\\)的普通布朗运动：\n$$ dx = adt + bdz = adt + b\\varepsilon \\sqrt{dt} $$\n其中\\(dz\\)遵循标准布朗运动。\n伊藤过程 将普通布朗运动中的\\(a\\)和\\(b\\)当作随时间\\(t\\)和状态\\(x\\)的函数，可以得到伊藤过程（Ito Process）：\n$$ dx = a(x,t)dt + b(x,t)dz $$\n证券价格的变动过程 终于又回到证券上了。（无收益）证券价格的变化可以用漂移率为\\(\\mu S\\)、方差率为\\((\\sigma S)^2\\)的伊藤过程表示：\n$$ dS = \\mu Sdt + \\sigma Sdz $$\n两边同除以\\(S\\)有：\n$$ \\frac{dS}{S} = \\mu dt + \\sigma dz $$\n其中\\(S\\)表示证券价格，\\(\\mu\\)表示单位时间内以连续复利表示的预期收益率，\\(\\sigma^2\\)表示证券收益率在单位时间内的方差，\\(\\sigma\\)简称证券价格的波动率（Volatility）。\n在短时间\\(\\Delta t\\)后，证券价格比率的变化值\\(\\frac{\\Delta S}{S}\\)为：\n$$ \\frac{dS}{S} = \\mu \\Delta t + \\varepsilon \\sigma \\sqrt{\\Delta t} \\sim N(\\mu \\Delta t, \\sigma \\sqrt{\\Delta t}) $$\n伊藤引理 伊藤进一步推导出（过程查论文吧）：若变量\\(x\\)遵循伊藤过程，则变量\\(x\\)和\\(t\\)的函数\\(G\\)遵循下列过程：\n$$ dG = (\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{\\partial^2 G}{2\\partial x^2}b^2)dt + \\frac{\\partial G}{\\partial x}bdz $$\n比较上面的伊藤过程，可以发现函数\\(G\\)是遵循伊藤过程的，漂移率：\\(\\frac{\\partial G}{\\partial x}a + \\frac{\\partial G}{\\partial t} + \\frac{\\partial^2 G}{2\\partial x^2}b^2\\)，方差率：\\((\\frac{\\partial G}{\\partial x})^2b^2\\)。根据上面的推理，我们有：\n$$ dS = \\mu Sdt + \\sigma Sdz $$\n我们知道，衍生证券的价格是标的证券价格和时间的函数。根据伊藤引理，衍生证券的价格\\(G\\)应遵循过程：\n$$ dG = (\\frac{\\partial G}{\\partial S}\\mu S + \\frac{\\partial G}{\\partial t} + \\frac{\\partial^2 G}{2\\partial S^2}\\sigma^2S^2)dt + \\frac{\\partial G}{\\partial S}\\sigma Sdz $$\n比较前面两个式子可以知道，\\(S\\)和\\(G\\)都受同一个不确定性来源\\(dz\\)的影响，这个特点十分重要。\n证券价格的自然对数变化过程 令\\(G=\\ln S\\)，代入上式，则：\n$$ dG = (\\mu - \\frac{\\sigma^2}{2})dt+\\sigma dz $$\n可以发现证券价格对数\\(G\\)遵循普通布朗运动，有恒定的漂移率\\(\\mu - \\frac{\\sigma^2}{2}\\)和方差率\\(\\sigma^2\\)！\n令\\(t\\)时刻的\\(G\\)值为\\(\\ln S\\)，\\(T\\)时刻的\\(G\\)值为\\(\\ln S_T\\)，则\\(T - t\\)时间内\\(G\\)的变化为：\n$$ \\ln S_T - \\ln S \\sim N[(\\mu - \\frac{\\sigma^2}{2})(T-t), \\sigma \\sqrt{T-t}] $$\n因为\\(\\ln S\\)是定值，所以可以得到：\n$$ \\ln S_T \\sim N[\\ln S + (\\mu - \\frac{\\sigma^2}{2})(T-t), \\sigma \\sqrt{T-t}] $$\n这表明\\(S_T\\)服从对数正态分布，证券价格对数的不确定性（标准差）与时间长度的平方根成正比。\n布莱克-舒尔斯微分方程 由于衍生证券价格和标的证券价格都受同一种不确定性影响（\\(dz\\)），若匹配适当，这种不确定性可以相互抵消。因此布莱克和舒尔斯建立了一个包括一单位衍生证券空头和若干单位标的证券多头的投资组合。若数量适当，衍生和标的证券的盈利和亏损是可以抵消的，短时间内该投资组合无风险。在无套利机会的情况下，该投资组合的短期收益率一定等于无风险利率。\n推导布莱克-舒尔斯微分方程需要以下假设：\n 证券价格遵循几何布朗运动（可以放松为伊藤过程） 允许卖空标的证券 没有交易费用和税收 所有证券都是完全可分的 在衍生证券的有效期内的标的证券没有收益 不存在无风险套利的机会 证券交易和价格变动都是连续的 在衍生证券有效期内，无风险利率\\(r\\)为常数  由假设1，有：\n$$ dS = \\mu Sdt + \\sigma Sdz $$\n在时间间隔\\(\\Delta t\\)中，\n$$ \\Delta S = \\mu S\\Delta t + \\sigma S\\Delta z $$\n假设\\(f\\)是依赖于\\(S\\)的衍生证券的价格，则\\(f\\)是\\(S\\)和\\(t\\)的函数。由伊藤引理可得：\n$$ df = (\\frac{\\partial f}{\\partial S}\\mu S + \\frac{\\partial f}{\\partial t} + \\frac{\\partial^2 f}{2\\partial S^2}\\sigma^2S^2)dt + \\frac{\\partial f}{\\partial S}\\sigma Sdz $$\n在时间间隔\\(\\Delta t\\)中，\n$$ \\Delta f = (\\frac{\\partial f}{\\partial S}\\mu S + \\frac{\\partial f}{\\partial t} + \\frac{\\partial^2 f}{2\\partial S^2}\\sigma^2S^2)\\Delta t + \\frac{\\partial f}{\\partial S}\\sigma S\\Delta z $$\n其中\\(\\Delta z = \\varepsilon \\sqrt{\\Delta t}\\)。为了消除\\(\\Delta z\\)，构建一个包括一单位衍生证券空头和\\(\\frac{\\partial f}{\\partial S}\\)单位标的证券多头的组合。令\\(\\Pi\\)代表该投资组合的价值，则：\n$$ \\Pi = -f + \\frac{\\partial f}{\\partial S}S $$\n在时间间隔\\(\\Delta t\\)中，\n$$ \\Delta \\Pi = -\\Delta f + \\frac{\\partial f}{\\partial S}\\Delta S $$\n代入\\(\\Delta S\\)和\\(\\Delta f\\)，可得：\n$$ \\Delta \\Pi = (-\\frac{\\partial f}{\\partial S} - \\frac{\\partial^2 f}{2\\partial S^2}\\sigma^2S^2)\\Delta t $$\n不含有\\(\\Delta z\\)，所以该组合在\\(\\Delta t\\)内没有风险。因为不存在无风险套利的机会，所以在\\(\\Delta t\\)内的瞬时收益率一定等于\\(\\Delta t\\)中的无风险收益率。因此：\n$$ \\Delta \\Pi = r \\Pi \\Delta t $$\n代入\\(\\Delta \\Pi\\)和\\(\\Pi\\)，得：\n$$ (\\frac{\\partial f}{\\partial t} + \\frac{\\partial^2 f}{2\\partial S^2}\\sigma^2S^2)\\Delta t = r (f - \\frac{\\partial f}{\\partial S}S \\Delta t $$\n化简得：\n$$ \\frac{\\partial f}{\\partial t} + rS\\frac{\\partial f}{\\partial S} + \\frac{1}{2}\\sigma^2S^2\\frac{\\partial^2 f}{\\partial S^2} = rf $$\n这就是著名的布莱克-舒尔斯微分方程，适用于其价格取决于标的证券价格\\(S\\)的所有衍生证券的定价。\n布莱克-舒尔斯期权定价公式 在风险中性的条件下，欧式看涨期权到期时（\\(T\\)）的期望值为：\n$$ \\hat E[max(S_T-X, 0)] $$\n根据风险中性定价原理，欧式看涨期权的价格\\(c\\)等于将此期望值按无风险利率进行贴现后的现值：\n$$ c = e^{-r(T-t)} \\hat E[max(S_T-X, 0)] $$\n根据前面，\\(\\ln S_T\\)符合分布\n$$ \\ln S_T \\sim N[\\ln S + (\\mu - \\frac{\\sigma^2}{2})(T-t), \\sigma \\sqrt{T-t}] $$\n在风险中性条件下，我们可以用\\(r\\)取代\\(\\mu\\)，即：\n$$ \\ln S_T \\sim N[\\ln S + (r - \\frac{\\sigma^2}{2})(T-t), \\sigma \\sqrt{T-t}] $$\n对\\(c\\)式右边求值是一种积分过程（过程略），结果为：\n$$ c=SN(d_1)-Xe^{-r(T-t)}N(d_2) $$\n其中，\n$$ d_1 = \\frac{\\ln \\frac{S}{X} + (r+\\frac{\\sigma^2}{2})(T-t)}{\\sigma \\sqrt{T-t}} $$ $$ d_2 = \\frac{\\ln \\frac{S}{X} + (r-\\frac{\\sigma^2}{2})(T-t)}{\\sigma \\sqrt{T-t}} $$\n\\(N(x)\\)是标准正态分布变量的累计概率分布函数。\n这就是无收益资产欧式看涨期权的定价公式。\n由售出-购进平价理论可以进一步导出欧式看跌期权的定价公式：\n$$ p=-SN(-d_1)+Xe^{-r(T-t)}N(-d_2) $$\n美式看涨期权不会提前行权，所以其定价与欧式看涨期权一致。而由于美式看跌期权与看涨期权之间不存在严密的平价关系，因此美式看跌期权的代价还没有得到一个精确的解析公式，但可用蒙特卡罗模拟、二叉树和有限差分三种数值方法以及解析近似方法求出。\n有收益资产的期权定价公式 在收益已知的情况下，可以把标的证券的价格分解成两个部分：期权有效期内已知的现金收益的现值部分，和一个有风险部分。当期权到期时，这部分现值将由于标的资产支付现金收益而消失。因此，我们只要用\\(S\\)表示有风险部分的证券价格，\\(\\sigma\\)表示风险部分遵循随机过程的波动率，就能直接套用公式了。\n当标的证券的已知收益的现值为\\(I\\)时，需要用\\((S-I)\\)代替公式的\\(S\\)。\n当标的证券的收益为按连续复利计算的固定收益率\\(q\\)时，需要用\\(Se^{-q(T-t)}\\)代替公式的\\(S\\)即可。\n","date":"2018-12-11T22:05:54+01:00","permalink":"http://xpgreat.com/p/%E5%B8%83%E8%8E%B1%E5%85%8B-%E8%88%92%E5%B0%94%E6%96%AF%E6%9C%9F%E6%9D%83%E5%AE%9A%E4%BB%B7%E6%A8%A1%E5%9E%8B/","title":"布莱克-舒尔斯期权定价模型"},{"content":"售出-购进平价理论（Put-Call Parity）指在无套利原则下（Non-Arbitrage），欧式看涨期权（Call Option）和欧式看跌期权（Put Option）定价之间存在的基本关系。\n看涨/看跌期权 看涨期权，Call Option，也被称为买进期权，买方期权，买权，延买期权或“敲进”（Knock In），是指期权的购买者拥有在期权合约规定有效期内按照执行价格购买 一定数量的标的物的权利。\n看跌期权，Put Option，也被称为认沽期权、卖出期权、出售期权、卖权选择权、卖方期权、卖权、延卖期权或“敲出”（Knock Out），是指期权的购买者拥有在期权合约规定有效期内按照执行价格卖出 一定数量的标的物的权利。\n举个例子，买家以20元购买了卖家的看涨期权，约定在一年后执行，执行价格为1500元，标的物是一吨铜。一年后铜的价格涨至2000元一吨，买家行使期权，以执行价格1500从卖家购买一吨铜（价值2000），获利2000-1500-20*K（K为贴现系数），卖家亏损2000-1500-20*K。如果一年后铜的价格跌至1300元一吨， 买家不行使期权，亏损20*K，卖家获利20*K。\n改动一下，买家以20元购买了卖家的看跌期权，约定在一年后执行，执行价格为1500元，标的物是一吨铜。一年后铜的价格跌至1300元一吨，买家行使期权，以执行价格1500向卖家售出一吨铜（价值1300），获利1500-1300-20*K（K为贴现系数），卖家亏损1500-1300-20*K。如果一年后铜的价格涨至2000元一吨， 买家不行使期权，亏损20*K，卖家获利20*K。\n推广可得，在期权行使时间看涨期权的获利/亏损可以表示为：\n$$ \\max (0, S_T - E) - q^np $$\n其中，\\(S_T\\)是现价，\\(E\\)是执行价格，\\(q\\)是利率，\\(p\\)是购买权力费用，\\(n = T-t\\)是执行时间。\n看跌期权的获利/亏损则为：\n$$ \\max (0, E - S_T) - q^np $$\n由此可见，期权买方有权利无义务，风险有限，最大损失是权利金，对于看涨期权，理论获利无上限，对于看跌期权，获利是有限的。而期权卖方有义务无权利，获利是有限的，而对于看涨期权，风险无限，对于看跌期权，风险有限。\n另外，期权分为美式期权和欧式期权，区别在于美式期权可以在到期日前任何时间行使权力，而欧式期权只能在到期日行使权力。但欧式期权可以在任何时间转让期权。\n售出-购进平价理论 考虑两个投资组合：\n  买入一份欧式看涨期权，卖出一份欧式看跌期权，执行价格\\(E\\)，无股息。\n  买入一单位标的物股权，借入\\(\\frac{E}{q}\\)债券。\n  对于1，如果到期标的物价格下跌，不行使看涨期权，看跌期权买家行使权力，需要以执行价格\\(E(\u0026gt;S_T)\\)买入；如果价格上涨，行使看涨期权，看跌期权买家不行使权力，以执行价格\\(E(\u0026lt;S_T)\\)买入，两个情况结果一致，相当于支付价值\\(S_T-E\\)。\n对于2，期权到期（\\(T\\)）时，一单位标的物股权和债券的支付价值也为\\(S_T - q\\frac{E}{q} = S_T - E\\)。\n基于无套利原则，在\\(T\\)时两个投资组合的支付价值一致，在之前的每个时间的价值也应该是一致的。所以在初始状态\\(t\\)时，有：\n$$ c-p=S_t-\\frac{E}{q} $$\n其中\\(c\\)，\\(p\\)分别表示看跌/看涨期权的现价，\\(S_t\\)标的物的现价，\\(E\\)执行价格，\\(q\\)利率。\n美式期权的提前行权 美式期权可以在到期日前任何时间行使权力。根据售出-购进平价理论有：\n$$ c=p+S_t-\\frac{E}{q^n} \\geq S_t-\\frac{E}{q^n} \\geq S_t-E $$\n因为现价永远大于执行价格，所以提前行使期权不值得。美式看涨期权基本不可能提前行权。这样可以得出美式看涨期权的定价和欧式一致。\n而：\n$$ p=c-S_t+\\frac{E}{q^n} \\ ? \\ E - S_t $$\n大小关系未知，所以美式看跌期权有可能提前行权。\n","date":"2018-12-07T21:48:39+01:00","permalink":"http://xpgreat.com/p/%E5%94%AE%E5%87%BA-%E8%B4%AD%E8%BF%9B%E5%B9%B3%E4%BB%B7%E7%90%86%E8%AE%BA/","title":"售出-购进平价理论"},{"content":"相信自己搭建博客的人中有一大半都是玩代码的，所以代码高亮可以说是博客的必备功能。本文提供一个在基于Hugo的博客上使用highlight.js的代码高亮方案。\n实施步骤  在highlight.js的官方网站上复制HTML的link和script标签。例如：  \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css\u0026quot;\u0026gt; \u0026lt;script src=\u0026quot;//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  打开themes/yourtheme/layouts/_default目录，打开baseof.html，（可能对不同主题文件和路径会有不同，如果找不到可以试试查找head.html或header.html。这个html文件是网页的head部分的模板。在合适的地方粘贴第一步中的代码。\n  大功告成。\n  使用 用```包裹代码块，保险起见，在```后加上语言名字。例如（不包括方括号内）：\n[START HERE] ```c int hash(char * str, int length) { // hash function int hash = 0; for (int i = 0; i \u0026lt; length; i++) { hash = ((hash + str[i]) * 31) % MAX_ID; // maximum of ID? } return hash; } ```[END HERE] 显示效果如下：\nint hash(char * str, int length) { // hash function  int hash = 0; for (int i = 0; i \u0026lt; length; i++) { hash = ((hash + str[i]) * 31) % MAX_ID; // maximum of ID?  } return hash; } 注意事项   如果要使用的语言很生僻，链接内的js和css可能无法满足需求，可以添加新的script，比如：https://cdn.bootcss.com/highlight.js/9.12.0/languages/yaml.min.js。或者在highlight.js的官方网站上自定义并下载下来，用本地引用。\n  如果需要修改颜色、背景色等样式，可以把css下载下来，修改后本地引用。修改后的css放在themes/yourtheme/static/css里，用href=\u0026quot;/css/highlight.css\u0026quot;引用。强烈建议在css里把背景色去除。\n ","date":"2018-12-05T19:31:24+01:00","permalink":"http://xpgreat.com/p/%E5%9C%A8hugo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8A%A0%E5%85%A5%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE/","title":"在Hugo博客中加入代码高亮"},{"content":"在编辑博文的时候，有时会想把两张图片并列在一起显示，参考了网上内容，分享一下。\n首先记住一点，在markdown里是可以直接写html代码的。这个前提下很自然的有下面的方法：\n调整图片宽度/高度： \u0026lt;img src=\u0026quot;http://xxx.jpg\u0026quot; title=\u0026quot;xxx\u0026quot; width=\u0026quot;100\u0026quot; height=\u0026quot;100\u0026quot;/\u0026gt; 宽度是 width，高度是 height，title 为图片描述。\n单张居中显示： \u0026lt;center\u0026gt; \u0026lt;img src=\u0026quot;http://example.com/xxx.png\u0026quot;\u0026gt; \u0026lt;/center\u0026gt; 或者：\n\u0026lt;figure\u0026gt; \u0026lt;img src=\u0026quot;http://xxx.jpg\u0026quot;\u0026gt; \u0026lt;/figure\u0026gt; 两张并排显示： \u0026lt;figure class=\u0026quot;half\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;http://xxx.jpg\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;http://xxx.jpg\u0026quot;\u0026gt; \u0026lt;/figure\u0026gt; 三张并排显示： \u0026lt;figure class=\u0026quot;third\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;http://xxx.jpg\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;http://xxx.jpg\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;http://xxx.jpg\u0026quot;\u0026gt; \u0026lt;/figure\u0026gt; ","date":"2018-12-05T17:42:53+01:00","permalink":"http://xpgreat.com/p/markdown%E9%87%8C%E5%9B%BE%E7%89%87%E5%B9%B6%E5%88%97%E6%98%BE%E7%A4%BA/","title":"Markdown里图片并列显示"},{"content":"对比以前搭建WordPress博客的经历，Hugo有这样的一些不同：\n  Hugo生成的是静态页面，所以没有内置的评论、搜索、登陆等等一系列的需要后台的功能。\n  没有WordPress上那么多五花八门的插件。\n  主题偏少，但足够。\n  使用起来有些门槛，比如必须会markdown，最好有一点HTML、 CSS的知识。但比起WordPress，学习起来快很多。\n  备份起来比WordPress简单（？），WordPress得用插件。\n  管理简单，因为只有基本的功能。\n  所以如果要搭建个人博客，Hugo十分足够。如果是喜欢图形化的编辑，喜欢尝试各种各样的主题插件（喜新厌旧），需要能方便的互动的，推荐WordPress。如果搭建组织网站，比如社团网站，需要多人、多层管理维护的，上WordPress，不用考虑Hugo了。\n","date":"2018-12-05T17:38:52+01:00","permalink":"http://xpgreat.com/p/hugo%E5%92%8Cwordpress%E6%AF%94%E8%BE%83/","title":"Hugo和WordPress比较"},{"content":"一些在使用Hugo时发现的小技巧或问题及解决方法，会持续更新。\n如何插入本地图片？ 一直不知道怎样插入本地图片，查找后得知，在site目录下的static目录就是存放静态文件的地方，可以在下面创建一个media目录，用于保存图片等媒体文件，引用的话，使用/media/123.png即可。\n注意：不要使用大写的后缀名，如123.PNG，生成的静态页面引用的是小写后缀，会出现找不到文件。\n搜索引擎无法搜索到博客内容。 这是因为搜索引擎还没有收录我们的URL，可以在搜索引擎提交一下自己的网址，比如谷歌，并过一段时间再试。\nHugo不支持站内搜索和内置评论。 这是因为Hugo生成的是静态网站，没有服务器后台，没有数据库，所以当然不能搜索和评论啦。如果你的网站被搜索引擎收录了，可以使用搜索引擎的限制搜索，比如serchword site:https://yoursite.com/，有的主题提供搜索框工具，基本也是靠这种方法。评论可以使用外置的评论系统，比如Discus。\nGit push的时候会发生冲突。 可能是在GitHub上配置自定义页面的时候（我就是在这时遇到的），repository里创建了新的文件（我碰到的是CNAME文件）而本地没有。解决方法是先pull再push。\nHugo报错。 肯定是在配置文件或者是文章头部配置有问题，具体查看报错信息进行修改即可，Hugo的报错做的不错，很好理解。\n访问的时候浏览器提示“不安全”。 这是因为没有启用HTTPS，如果是托管在GitHub上的话可以使用GitHub提供的HTTPS福利。开启步骤如下：\n 找到处于不可选状态的Enforce HTTPS选项，旁边会提示 Unavailable for your site because your domain is not properly configured to support HTTPS 。 将填在Custom domain里的自定义域名清空，保存，然后重新填上自定义域名，再保存。 现在可以勾选Enforce HTTPS选项了，这时会提示正在签发证书: Not yet available for your site because the certificate has not finished being issued 。 证书签发成功后，可以使用 https 链接访问自定义域名了。  DNS配置完成后，还不能访问页面，或者有的设备可以访问，而有的不行。 这是因为DNS需要一定时间传播，等待一段时间就好了。有兴趣可以阅读一下DNS的维基百科。\nsvg绘图标 左边栏的Utils图标代码：\n\u0026lt;svg xmlns=\u0026quot;http://www.w3.org/2000/svg\u0026quot; class=\u0026quot;icon icon-tabler icon-tabler-search\u0026quot; width=\u0026quot;24\u0026quot; height=\u0026quot;24\u0026quot; viewBox=\u0026quot;0 0 24 24\u0026quot; stroke-width=\u0026quot;2\u0026quot; stroke=\u0026quot;currentColor\u0026quot; fill=\u0026quot;none\u0026quot; stroke-linecap=\u0026quot;round\u0026quot; stroke-linejoin=\u0026quot;round\u0026quot;\u0026gt; \u0026lt;path stroke=\u0026quot;none\u0026quot; d=\u0026quot;M0 0h24v24H0z\u0026quot;\u0026gt;\u0026lt;/path\u0026gt; \u0026lt;line x1=\u0026quot;10\u0026quot; y1=\u0026quot;18\u0026quot; x2=\u0026quot;23\u0026quot; y2=\u0026quot;5\u0026quot;\u0026gt;\u0026lt;/line\u0026gt; \u0026lt;line x1=\u0026quot;10\u0026quot; y1=\u0026quot;18\u0026quot; x2=\u0026quot;3\u0026quot; y2=\u0026quot;9\u0026quot;\u0026gt;\u0026lt;/line\u0026gt; \u0026lt;/svg\u0026gt; ","date":"2018-12-05T16:32:54+01:00","permalink":"http://xpgreat.com/p/%E4%BD%BF%E7%94%A8hugo%E7%9A%84%E4%B8%80%E4%BA%9B%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","title":"使用Hugo的一些注意事项"},{"content":"Hugo是一个用Go编写的静态站点生成器，由于具有丰富的主题资源和惊人的生成速度而备受青睐。博文采用Markdown这一轻量的标记语言编写，速度快，美观。本博客即是基于Hugo搭建，下面讲述一下我的建站历程。\n安装Hugo 如果你是macOS用户，请使用Homebrew快速安装\nbrew install hugo 如果你是Windows用户，请使用Chocolatey或者Scoop快速安装，取决于你使用什么包管理\nchoco install hugo -confirm scoop install hugo 如果你是Debian或Ubuntu用户，请使用apt快速安装\nsudo apt-get install hugo 基本上使用单行命令都可以成功安装Hugo，具体请移步这里。\n生成第一篇文章 使用如下命令新建一个名为“mysite”的网站：\nhugo new site mysite 接下来，在这里找到一个漂亮的网站主题。主题极其之多，找到一个满意的并不难。本博客采用的是Mainroad主题。如果对主题的配色之类的不满意，可以通过修改style.css这一文件来达到想要的效果。\n以Mainroad为例，将主题clone到本地的themes文件夹内：\ncd themes git clone https://github.com/Vimux/Mainroad.git mysite/content是用来存放文档的地方，我们在其下建立一个新的Markdown文件：\nhugo new post/first.md 在first.md中写入一些内容，使用如下命令进行本地预览：\nhugo server -t mainroad -D 打开网址 http://localhost:1313/ 即可查看本地生成的静态网站。\n适配主题 Hugo的每个主题都会有不同的参数配置，而这些配置被存放在根目录下的config.toml文件中，以Mainroad为例，官方的GitHub里已经做了说明：\nbaseurl = \u0026quot;/\u0026quot; title = \u0026quot;Mainroad\u0026quot; languageCode = \u0026quot;en-us\u0026quot; paginate = \u0026quot;10\u0026quot; # Number of posts per page theme = \u0026quot;mainroad\u0026quot; disqusShortname = \u0026quot;\u0026quot; # Enable comments by entering your Disqus shortname googleAnalytics = \u0026quot;\u0026quot; # Enable Google Analytics by entering your tracking id [Author] # Used in authorbox name = \u0026quot;John Doe\u0026quot; bio = \u0026quot;John Doe's true identity is unknown. Maybe he is a successful blogger or writer. Nobody knows it.\u0026quot; avatar = \u0026quot;img/avatar.png\u0026quot; [Params] subtitle = \u0026quot;Just another site\u0026quot; # Subtitle of your site. Used in site header description = \u0026quot;John Doe's Personal blog about everything\u0026quot; # Site description. Used in meta description #copyright = \u0026quot;John Doe\u0026quot; # copyright holder, otherwise will use site title opengraph = true # Enable OpenGraph if true twitter_cards = true # Enable Twitter Cards if true readmore = false # Show \u0026quot;Read more\u0026quot; button in list if true authorbox = true # Show authorbox at bottom of pages if true toc = true # Enable Table of Contents post_navigation = true # Show post navigation at bottom of pages if true # post_meta = [\u0026quot;date\u0026quot;, \u0026quot;categories\u0026quot;] # Order of post meta information. Use [\u0026quot;none\u0026quot;] to turn off completely. postSections = [\u0026quot;post\u0026quot;] # the section pages to show on home page and the \u0026quot;Recent articles\u0026quot; widget #postSections = [\u0026quot;blog\u0026quot;, \u0026quot;news\u0026quot;] # alternative that shows more than one section's pages #dateformat = \u0026quot;2006-01-02\u0026quot; # change the format of dates #mathjax = true # Enable MathJax #mathjaxPath = \u0026quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js\u0026quot; # Specify MathJax path #mathjaxConfig = \u0026quot;TeX-AMS-MML_HTMLorMML\u0026quot; # Specify MathJax config [Params.sidebar] home = \u0026quot;right\u0026quot; # Configure layout for home page list = \u0026quot;left\u0026quot; # Configure layout for list pages single = false # Configure layout for single pages # Enable widgets in given order widgets = [\u0026quot;search\u0026quot;, \u0026quot;recent\u0026quot;, \u0026quot;categories\u0026quot;, \u0026quot;taglist\u0026quot;, \u0026quot;social\u0026quot;] [Params.widgets] recent_num = 5 # Set the number of articles in the \u0026quot;Recent articles\u0026quot; widget tags_counter = false # Enable counter for each tag in \u0026quot;Tags\u0026quot; widget (disabled by default) [Params.widgets.social] # Enable parts of social widget facebook = \u0026quot;username\u0026quot; twitter = \u0026quot;username\u0026quot; instagram = \u0026quot;username\u0026quot; linkedin = \u0026quot;username\u0026quot; telegram = \u0026quot;username\u0026quot; github = \u0026quot;username\u0026quot; gitlab = \u0026quot;username\u0026quot; bitbucket = \u0026quot;username\u0026quot; email = \u0026quot;example@example.com\u0026quot; google_plus = \u0026quot;profileid\u0026quot; 在每一篇博文前也有一个Header，官方提供的样例为：\n--- title: \u0026quot;Example article title\u0026quot; date: \u0026quot;2017-08-21\u0026quot; description: \u0026quot;Example article description\u0026quot; thumbnail: \u0026quot;img/placeholder.jpg\u0026quot; # Optional, thumbnail lead: \u0026quot;Example lead - highlighted near the title\u0026quot; disable_comments: false # Optional, disable Disqus comments if true authorbox: true # Optional, enable authorbox for specific post toc: true # Optional, enable Table of Contents for specific post mathjax: true # Optional, enable MathJax for specific post categories: - \u0026quot;Category 1\u0026quot; - \u0026quot;Category 2\u0026quot; tags: - \u0026quot;Test\u0026quot; - \u0026quot;Another test\u0026quot; menu: main # Optional, add page to a menu. Options: main, side, footer --- 可以把Header的内容复制到mysite//archetypes/default.md中，这样新建新文档的时候才会适应你的主题的结构。如果在写草稿，为了不让它在博客里显示，需要在Header里加入：\ndraft: true 发布网站到GitHub Pages 在使用hugo server -D预览网站无误后可正式发布网站到域名供大家浏览。将要发布的文章内draft改为false后执行命令\nhugo 可看到根目录下多出/public文件夹出来，该文件夹的内容即Hugo生成的整个静态网站。最终我们需要把这些静态网站的文件部署到一个地方，免费且稳定的GitHub Pages是一个很好的选择。具体操作如下：\n 在GitHub新建一个Repository命名为Example.github.io，其中Example改成自己的GitHub账户名； 在/mysite外建立一个平行的文件夹，此处假设也命名为/Example.github.io； 进入/public文件夹将内容复制到/Example.github.io； 将/Example.github.io的内容push到远程仓库。  以上命令可在命令行通过以下语句实现：\nmkdir Example.github.io cd mysite/public cp -r . ../../Example.github.io cd ../../Example.github.io git init git add . git commit -m \u0026quot;commit message\u0026quot; git remote add origin https://github.com/Example/Example.github.io.git git push -u origin master 完成以上命令后，等待一分钟左右即可在 https://Example.github.io/ 访问你的网站。 以后每次更新文章后只用将生成的/public文件夹的静态网站内容复制到/Example.github.io，然后再push到远程仓库即可。也可将步骤写为Shell脚本，此处不再赘述。\n使用自己的域名 当然，GitHub的域名怎么能满足装*的心理，这时可以将网站设置为自己的域名。购买域名的地方很多，如国外知名网站GoDaddy，简体中文页面、支持支付宝付款、不用备案等都带来了很多方便。关于如何将域名定向到自己的页面，请参阅\n将网页托管到GitHub还有一个好处，可以设置强制https协议，这样你的网站就不会被识别成不安全啦。\nTips：\n  Markdown可以用很多编辑器编辑，我使用的是Sublime Text，十分好用。\n  如果嫌打开Bash麻烦可以把命令写成.sh或.bat文件方便操作。\n ","date":"2018-12-03T19:58:50+01:00","permalink":"http://xpgreat.com/p/%E5%8D%9A%E5%AE%A2%E7%AC%AC%E4%B8%80%E6%AD%A5/","title":"博客第一步"}]