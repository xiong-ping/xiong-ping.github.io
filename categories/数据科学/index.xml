<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据科学 on XP&#39;s Blog</title>
    <link>https://xpgreat.com/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/</link>
    <description>Recent content in 数据科学 on XP&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 17 Aug 2021 20:34:54 +0200</lastBuildDate><atom:link href="https://xpgreat.com/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hamiltonian Monte Carlo算法</title>
      <link>https://xpgreat.com/p/hmc/</link>
      <pubDate>Tue, 17 Aug 2021 20:34:54 +0200</pubDate>
      
      <guid>https://xpgreat.com/p/hmc/</guid>
      <description>&lt;p&gt;MCMC（Markov-Chain Monte-Carlo）算法用于生成给定分布的样本。在很多时候，我们想计算一个复杂分布的函数期望值，但用解析的，求解积分的方法，是极其困难的，对于有些分布甚至是不可能的。所以我们使用一些采样方法，例如Gibbs sampling，Metropolis-Hasting算法。本文介绍Hamiltonian Monte-Carlo算法。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>搭建真分布式Hadoop集群指南</title>
      <link>https://xpgreat.com/p/hadoop_aws/</link>
      <pubDate>Mon, 29 Mar 2021 10:39:10 +0200</pubDate>
      
      <guid>https://xpgreat.com/p/hadoop_aws/</guid>
      <description>&lt;p&gt;搭建一个Hadoop环境是学习大数据技术的第一步，这个环境可以是单机的，也可以是伪集群的，但最贴近实际生产环境的还是真集群的版本。本文提供一个基于AWS搭建Hadoop的简要指南，基于AWS EC2 Ubuntu 20。如果你也用的是AWS的免费套餐，几个注意的地方：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;小心流量使用情况，免费的仅包括了15G，请设置使用提醒。&lt;/li&gt;
&lt;li&gt;选择机器配置的时候注意选择免费套餐内的，否则也会扣费。&lt;/li&gt;
&lt;li&gt;免费套餐包括EC2每个月750h/台的使用时间，开多台实例的话注意不要超时，可以随用随开，不用就关。&lt;/li&gt;
&lt;li&gt;关闭后再启动公有IP会变，注意配置问题。&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>利用sklearn构建tfidf向量</title>
      <link>https://xpgreat.com/p/tfidf_python/</link>
      <pubDate>Tue, 24 Nov 2020 11:22:02 +0800</pubDate>
      
      <guid>https://xpgreat.com/p/tfidf_python/</guid>
      <description>在自然语言处理中，第一步需要面对的就是词向量特征的提取。语言的特征提取在sklearn模块中有相当完善的方法和模块，本文先利用CountVectorizer提取词汇，再用TfidfTransformer计算TFIDF向量。之所以选择CountVectorizer而不自行写一个代码，是因为在使用时维度很容易超过10w，产生的bag-of-words向量特别稀疏，需要耗费极大的内存，而sklearn实现了一个稀疏矩阵的存储形式，可以极大的加速和降低消耗。
构建Bag-of-words词汇矩阵 from sklearn.feature_extraction.text import CountVectorizer #测试用字符串list s_l = [&amp;#39;Relevant words for each class or cluster are identified by computing a relevancy score rc for every word ti based on the documents in the class&amp;#39;, &amp;#39;or cluster and then selecting the highest scoring&amp;#39;, &amp;#39;words. These scores can be computed either by-89&amp;#39;, &amp;#39;aggregating the raw tf-idf features of all documents&amp;#39;, &amp;#39;in the group (Section 2.3.1), by aggregating these&amp;#39;, &amp;#39;features weighted by some classifier’s parameters&amp;#39;, &amp;#39;(Section 2.</description>
    </item>
    
    <item>
      <title>论文解读：Exploring text datasets by visualizing relevant words</title>
      <link>https://xpgreat.com/p/explore_text_dataset/</link>
      <pubDate>Thu, 19 Nov 2020 15:14:26 +0800</pubDate>
      
      <guid>https://xpgreat.com/p/explore_text_dataset/</guid>
      <description>&lt;p&gt;在做机器学习使用新数据集时，我们首先要知道它的特点，一个可以快速可靠地深入了解所选文档的内容，并区分它们类别的工具十分重要。 在这篇论文，作者从文本集合中提取“相关词”，以概括属于某个类别（或在unlabeled数据集下为聚类的组）的文档的内容，并在词云中可视化它们。 作者比较了三种提取相关单词的方法，并使用两个数据集验证了模型的可用性。&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1707.05261.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;论文链接&lt;/a&gt;，&lt;a class=&#34;link&#34; href=&#34;https://github.com/cod3licious/textcatvis&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;论文代码&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hive窗口函数总结</title>
      <link>https://xpgreat.com/p/hive_windowfunc/</link>
      <pubDate>Thu, 29 Oct 2020 11:01:26 +0800</pubDate>
      
      <guid>https://xpgreat.com/p/hive_windowfunc/</guid>
      <description>&lt;p&gt;窗口函数是对Hive的一项增强，用来更方便地分析离线数据。窗口函数的使用场景非常之多，包括去重、排名、分组求和等等。本文希望尽可能全面的归纳窗口函数的用法，以便日后的查阅。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>机器学习的工作流程</title>
      <link>https://xpgreat.com/p/workflow_ml/</link>
      <pubDate>Sun, 15 Mar 2020 16:25:12 +0800</pubDate>
      
      <guid>https://xpgreat.com/p/workflow_ml/</guid>
      <description>&lt;p&gt;最近在阅读François Chollet写的Deep Learning with Python. 书中有很多经验性的技巧和归纳，其中4.5写的Machine Learning的工作流程归纳的很好，看完深有启发，摘录于此。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>中短期电价预测模型简介</title>
      <link>https://xpgreat.com/p/epf_models/</link>
      <pubDate>Sat, 25 May 2019 17:35:01 +0200</pubDate>
      
      <guid>https://xpgreat.com/p/epf_models/</guid>
      <description>&lt;p&gt;从1981年的智利电力体制改革之后，英美等国先后进行了电力工业重组，这些努力导致了电力工业的市场化，促成了电力市场的形成，实现了资源的合理分配和社会效益的最大化。准确的电力价格对发电商、用户、监管者具有重要的意义。本文将常用的电价预测（EPF, Electricity Price Forecasting）模型进行了分类，并加以简介。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>递归神经网络</title>
      <link>https://xpgreat.com/p/rnn_lstm_gru/</link>
      <pubDate>Tue, 14 May 2019 10:48:15 +0200</pubDate>
      
      <guid>https://xpgreat.com/p/rnn_lstm_gru/</guid>
      <description>&lt;p&gt;递归神经网络是神经网络的一种，与其他神经网络不同点在于，它可以很好地处理序列数据，即前面的数据的输入与后面的输出是有关系的，比如一句话的语义理解。本文介绍了递归神经网络及其两个变种——LSTM和GRU，目的是梳理一下自己所理解的RRN，也希望能够给初次接触RRN的同学一点帮助。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>机器学习中的矩阵求导</title>
      <link>https://xpgreat.com/p/linalg_in_ml/</link>
      <pubDate>Thu, 17 Jan 2019 21:47:14 +0100</pubDate>
      
      <guid>https://xpgreat.com/p/linalg_in_ml/</guid>
      <description>&lt;p&gt;在学习机器学习的算法时，推导过程中往往会涉及矩阵或向量求导以及一些其他的线性代数的知识。比如在推导LDA算法的时候，就是把Fisher&amp;rsquo;s Criterion求导后置零得到的结果。另外在优化的时候经常会使用到梯度下降法，这与矩阵向量求导也是分不开的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>认知算法小结</title>
      <link>https://xpgreat.com/p/ca_short_summary/</link>
      <pubDate>Fri, 28 Dec 2018 20:57:51 +0100</pubDate>
      
      <guid>https://xpgreat.com/p/ca_short_summary/</guid>
      <description>&lt;p&gt;在认知算法课里学习了一些算法，比如NCC，感知算法，LDA等等，小结一下。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
